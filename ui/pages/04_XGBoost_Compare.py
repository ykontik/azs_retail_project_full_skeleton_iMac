import os
from pathlib import Path
from typing import List, Optional

import joblib
import numpy as np
import pandas as pd
import streamlit as st

from make_features import make_features

st.set_page_config(page_title="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ: XGBoost vs LGBM", layout="wide")
st.title("üÜö –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: Global XGBoost vs per-SKU LGBM")

RAW_DIR = Path(os.getenv("RAW_DIR", "data_raw"))
MODELS_DIR = Path(os.getenv("MODELS_DIR", "models"))

@st.cache_data(show_spinner=False)
def load_raw():
    paths = {k: RAW_DIR / f"{k}.csv" for k in ["train", "transactions", "oil", "holidays_events", "stores"]}
    missing = [k for k, p in paths.items() if not p.exists()]
    if missing:
        return None, missing
    train = pd.read_csv(paths["train"], parse_dates=["date"])
    trans = pd.read_csv(paths["transactions"], parse_dates=["date"])
    oil = pd.read_csv(paths["oil"], parse_dates=["date"])
    hol = pd.read_csv(paths["holidays_events"], parse_dates=["date"])
    stores = pd.read_csv(paths["stores"])
    return (train, hol, trans, oil, stores), []

@st.cache_data(show_spinner=True)
def build_features():
    data, missing = load_raw()
    if data is None:
        return None, missing
    train, hol, trans, oil, stores = data
    Xfull, _ = make_features(train, hol, trans, oil, stores, dropna_target=True)
    for c in ["store_nbr","family","type","city","state","cluster","is_holiday"]:
        if c in Xfull.columns:
            Xfull[c] = Xfull[c].astype("category")
    bool_cols = Xfull.select_dtypes(include=["bool"]).columns.tolist()
    if bool_cols:
        Xfull[bool_cols] = Xfull[bool_cols].astype("int8")
    return Xfull, []

def model_feature_names(model) -> Optional[List[str]]:
    names = getattr(model, "feature_name_", None)
    if names is None and hasattr(model, "booster_"):
        try:
            names = list(model.booster_.feature_name())
        except Exception:
            names = None
    return names

def xgb_feature_names(model) -> Optional[List[str]]:
    """–î–æ—Å—Ç–∞—ë—Ç –∏–º–µ–Ω–∞ —Ñ–∏—á –∏–∑ XGBRegressor.
    –ü–æ—Ä—è–¥–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –∫—Ä–∏—Ç–∏—á–µ–Ω, –ø–æ—ç—Ç–æ–º—É –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–ª–∏ None.
    """
    names = getattr(model, "feature_names_in_", None)
    if names is not None:
        try:
            return list(names)
        except Exception:
            pass
    try:
        booster = model.get_booster()
        if hasattr(booster, "feature_names"):
            return list(booster.feature_names)
    except Exception:
        return None
    return None

from collections.abc import Sequence


def align_features(df: pd.DataFrame, required: Sequence[str], *, numeric: bool = False) -> pd.DataFrame:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ (0.0) –∏ –ø–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ—Ç —Å—Ç–æ–ª–±—Ü—ã –ø–æ–¥ –º–æ–¥–µ–ª—å.

    numeric=False ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–∏–ø—ã (–¥–ª—è LGBM —Å –∫–∞—Ç–µ–≥–æ—Ä. —Ñ–∏—á–∞–º–∏)
    numeric=True  ‚Äî –ø—Ä–∏–≤–æ–¥–∏—Ç –≤—Å–µ —Å—Ç–æ–ª–±—Ü—ã –∫ —á–∏—Å–ª—É (–¥–ª—è XGB –∏ –¥—Ä.)
    """
    out = df.copy()
    for col in required:
        if col not in out.columns:
            out[col] = 0.0
    out = out[required].copy()
    if numeric:
        try:
            out = out.apply(pd.to_numeric, errors="coerce").fillna(0.0)
        except Exception:
            pass
    return out

models = sorted([p for p in MODELS_DIR.glob("*.joblib") if ("__q" not in p.name) and ("global_xgboost" not in p.name)])
if not models:
    st.warning("–ù–µ—Ç per-SKU –º–æ–¥–µ–ª–µ–π. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.")
    st.stop()

# load global XGB
xgb_path = MODELS_DIR / "global_xgboost.joblib"
if not xgb_path.exists():
    st.warning("–ì–ª–æ–±–∞–ª—å–Ω–∞—è XGBoost –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: make train_global_xgb")
    st.stop()
mdl_xgb = joblib.load(xgb_path)

pairs = []
for mp in models:
    try:
        s, f = mp.stem.split("__", 1)
        pairs.append((int(s), f.replace("_", " ")))
    except Exception:
        continue
pairs = sorted(set(pairs))

st.sidebar.header("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã")
store_sel = st.sidebar.selectbox("store_nbr", sorted(set(s for s, _ in pairs)))
fam_opts = sorted([f for s, f in pairs if s == store_sel])
family_sel = st.sidebar.selectbox("family", fam_opts)
back_days = st.sidebar.slider("–î–Ω–µ–π –≤ —Ö–≤–æ—Å—Ç–µ", min_value=28, max_value=180, value=90, step=7)
period = st.sidebar.radio("–ü–µ—Ä–∏–æ–¥", ["–î–µ–Ω—å", "–ù–µ–¥–µ–ª—è", "–ú–µ—Å—è—Ü"], index=0)
min_tail_sales = st.sidebar.number_input("–ú–∏–Ω. —Å—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ö–≤–æ—Å—Ç–µ (—Ñ–∏–ª—å—Ç—Ä –ø–∞—Ä)", min_value=0, value=0, step=10)

Xfull, missing = build_features()
if Xfull is None:
    st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö: " + ", ".join(missing))
    st.stop()

mask = (Xfull["store_nbr"] == int(store_sel)) & (Xfull["family"] == family_sel)
df_pair = Xfull.loc[mask].sort_values("date").copy()
if df_pair.empty:
    st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø–∞—Ä—ã.")
    st.stop()

# per-SKU LGBM
lgb_path = MODELS_DIR / f"{int(store_sel)}__{str(family_sel).replace(' ', '_')}.joblib"
try:
    mdl_lgb = joblib.load(lgb_path)
except Exception:
    st.error(f"Per-SKU LGBM –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {lgb_path.name}")
    st.stop()
feat_lgb = model_feature_names(mdl_lgb)
for f in feat_lgb:
    if f not in df_pair.columns:
        df_pair[f] = 0.0

tail = df_pair.tail(int(back_days)).copy()
y_true = tail["sales"].values

# LGBM: —Å–≤–æ–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
X_lgb = align_features(tail, feat_lgb, numeric=False)
y_lgb = mdl_lgb.predict(X_lgb)

# XGB: —Å–≤–æ–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
feat_xgb = xgb_feature_names(mdl_xgb) or feat_lgb
X_xgb = align_features(tail, feat_xgb, numeric=True)
y_xgb = mdl_xgb.predict(X_xgb)

def agg_series(dates: pd.Series, y: np.ndarray, how: str):
    if how == "–î–µ–Ω—å":
        return dates, y
    freq = "W" if how == "–ù–µ–¥–µ–ª—è" else "M"
    df = pd.DataFrame({"date": dates.values, "y": y}).set_index("date").groupby(pd.Grouper(freq=freq)).sum().reset_index()
    return df["date"].values, df["y"].values

st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ (tail)")
def _metrics(y_true, y_pred):
    mae = float(np.mean(np.abs(y_true - y_pred)))
    denom = np.where(y_true == 0, 1, y_true)
    mape = float(np.mean(np.abs((y_true - y_pred) / denom)) * 100.0)
    return mae, mape
mae_l, mape_l = _metrics(y_true, y_lgb)
mae_x, mape_x = _metrics(y_true, y_xgb)
col1, col2 = st.columns(2)
with col1:
    st.metric("LGBM ‚Äî MAE", f"{mae_l:.2f}")
    st.metric("LGBM ‚Äî MAPE %", f"{mape_l:.2f}%")
with col2:
    st.metric("XGBoost ‚Äî MAE", f"{mae_x:.2f}")
    st.metric("XGBoost ‚Äî MAPE %", f"{mape_x:.2f}%")

st.subheader("–ì—Ä–∞—Ñ–∏–∫ (tail)")
import matplotlib.pyplot as plt

x_dates, y_true_agg = agg_series(tail["date"], y_true, period)
_, y_lgb_agg = agg_series(tail["date"], y_lgb, period)
_, y_xgb_agg = agg_series(tail["date"], y_xgb, period)
fig = plt.figure(figsize=(12,4))
plt.plot(x_dates, y_true_agg, label="–§–∞–∫—Ç")
plt.plot(x_dates, y_lgb_agg, label="LGBM")
plt.plot(x_dates, y_xgb_agg, label="XGBoost")
plt.title(f"–•–≤–æ—Å—Ç {int(back_days)} –¥–Ω., –ø–µ—Ä–∏–æ–¥: {period.lower()}")
plt.xlabel("–î–∞—Ç–∞/–ü–µ—Ä–∏–æ–¥"); plt.ylabel("–ü—Ä–æ–¥–∞–∂–∏")
plt.legend(); plt.grid()
st.pyplot(fig)

st.markdown("---")
st.subheader("Heatmap: XGBoost vs LGBM (–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ = XGB –ª—É—á—à–µ)")
max_pairs = st.slider("–ü–∞—Ä—ã –¥–ª—è heatmap (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ)", min_value=10, max_value=300, value=100, step=10)
pairs_all = pairs[:max_pairs]
rows = []
skipped = []
for (s, f) in pairs_all:
    try:
        mp = MODELS_DIR / f"{int(s)}__{str(f).replace(' ', '_')}.joblib"
        try:
            m = joblib.load(mp)
        except Exception as e:
            skipped.append({"store_nbr": s, "family": f, "reason": f"load per-SKU model failed: {e}"})
            continue
        feats = model_feature_names(m)
        df_p = Xfull[(Xfull["store_nbr"] == int(s)) & (Xfull["family"] == f)].sort_values("date").tail(int(back_days)).copy()
        if df_p.empty:
            skipped.append({"store_nbr": s, "family": f, "reason": "empty tail"}); continue
        if not feats:
            skipped.append({"store_nbr": s, "family": f, "reason": "no LGBM feature names"}); continue
        # LGBM
        Xl = align_features(df_p, feats, numeric=False)
        # XGB –ø–æ —Å–≤–æ–µ–º—É —Å–ø–∏—Å–∫—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feats_x = xgb_feature_names(mdl_xgb) or feats
        Xx = align_features(df_p, feats_x, numeric=True)
        y_t = df_p["sales"].values
        try:
            y_l = m.predict(Xl)
        except Exception as e:
            skipped.append({"store_nbr": s, "family": f, "reason": f"LGBM predict failed: {e}"}); continue
        try:
            y_x = mdl_xgb.predict(Xx)
        except Exception as e:
            skipped.append({"store_nbr": s, "family": f, "reason": f"XGB predict failed: {e}"}); continue
        # —Ñ–∏–ª—å—Ç—Ä –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Å—É–º–º–µ –ø—Ä–æ–¥–∞–∂ –≤ —Ö–≤–æ—Å—Ç–µ
        tail_sum = float(np.sum(y_t))
        if tail_sum < float(min_tail_sales):
            skipped.append({"store_nbr": s, "family": f, "reason": f"tail_sum<{min_tail_sales}"}); continue
        mae = float(np.mean(np.abs(y_t - y_l)))
        mape = float(np.mean(np.abs((y_t - y_l) / np.where(y_t == 0, 1, y_t))) * 100.0)
        mae_x = float(np.mean(np.abs(y_t - y_x)))
        mape_x = float(np.mean(np.abs((y_t - y_x) / np.where(y_t == 0, 1, y_t))) * 100.0)
        rows.append({
            "store_nbr": int(s),
            "family": f,
            "LGBM_MAE": round(mae, 2),
            "LGBM_MAPE": round(mape, 2),
            "XGB_MAE": round(mae_x, 2),
            "XGB_MAPE": round(mape_x, 2),
            "GAIN_XGB_vs_LGBM_MAE": round(mae - mae_x, 2),
            "GAIN_XGB_vs_LGBM_MAPE": round(mape - mape_x, 2),
        })
    except Exception:
        skipped.append({"store_nbr": s, "family": f, "reason": "unexpected exception"}); continue

if rows:
    dfm = pd.DataFrame(rows)
    dim_choice = st.radio("–†–∞–∑—Ä–µ–∑", ["–ü–æ –º–∞–≥–∞–∑–∏–Ω–∞–º", "–ü–æ —Å–µ–º–µ–π—Å—Ç–≤–∞–º"], horizontal=True)
    metric_choice = st.radio("–ú–µ—Ç—Ä–∏–∫–∞", ["MAE", "MAPE"], horizontal=True)
    dim_col = "store_nbr" if dim_choice == "–ü–æ –º–∞–≥–∞–∑–∏–Ω–∞–º" else "family"
    val_xgb = "GAIN_XGB_vs_LGBM_MAE" if metric_choice == "MAE" else "GAIN_XGB_vs_LGBM_MAPE"
    pv_xgb = dfm.pivot_table(index=dim_col, columns="family" if dim_col=="store_nbr" else "store_nbr", values=val_xgb, aggfunc="mean").fillna(0.0)
    pv_display = pv_xgb.round(2)
    st.dataframe(pv_display.style.background_gradient(cmap="RdYlGn"), use_container_width=True)
    st.download_button(
        "‚¨áÔ∏è CSV: heatmap XGB vs LGBM",
        data=pv_display.to_csv().encode("utf-8"),
        file_name="heatmap_xgb_vs_lgbm.csv",
        mime="text/csv",
    )
else:
    st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è heatmap.")

# –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏—á–∏–Ω—ã –ø—Ä–æ–ø—É—Å–∫–æ–≤ (–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞)
if skipped:
    with st.expander("–ü–∞—Ä—ã, –∏—Å–∫–ª—é—á—ë–Ω–Ω—ã–µ –∏–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞)", expanded=False):
        skipped_df = pd.DataFrame(skipped)
        st.dataframe(skipped_df.round(2), use_container_width=True)
