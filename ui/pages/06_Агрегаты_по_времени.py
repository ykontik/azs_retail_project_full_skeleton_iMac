import os
from pathlib import Path
from typing import List, Optional

import joblib
import pandas as pd
import streamlit as st

from make_features import make_features

st.set_page_config(page_title="–ê–≥—Ä–µ–≥–∞—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏", layout="wide")
st.title("üóìÔ∏è –ê–≥—Ä–µ–≥–∞—Ç—ã –æ—à–∏–±–æ–∫ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–µ–¥–µ–ª–∏/–º–µ—Å—è—Ü—ã)")

DATA_DIR = Path(os.getenv("RAW_DIR", "data_raw"))
MODELS_DIR = Path(os.getenv("MODELS_DIR", "models"))


@st.cache_data(show_spinner=False)
def load_raw():
    train = pd.read_csv(DATA_DIR / "train.csv", parse_dates=["date"])
    trans = pd.read_csv(DATA_DIR / "transactions.csv", parse_dates=["date"]) if (DATA_DIR/"transactions.csv").exists() else None
    oil = pd.read_csv(DATA_DIR / "oil.csv", parse_dates=["date"]) if (DATA_DIR/"oil.csv").exists() else None
    hol = pd.read_csv(DATA_DIR / "holidays_events.csv", parse_dates=["date"]) if (DATA_DIR/"holidays_events.csv").exists() else None
    stores = pd.read_csv(DATA_DIR / "stores.csv") if (DATA_DIR/"stores.csv").exists() else None
    return train, hol, trans, oil, stores


@st.cache_data(show_spinner=True)
def build_full_features():
    train, hol, trans, oil, stores = load_raw()
    Xfull, _ = make_features(train, hol, trans, oil, stores, dropna_target=True)
    # –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ ‚Äî –∫–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏
    for c in ["store_nbr","family","type","city","state","cluster","is_holiday"]:
        if c in Xfull.columns:
            Xfull[c] = Xfull[c].astype("category")
    # –±—É–ª–µ–≤—ã–µ –≤ int
    bool_cols = Xfull.select_dtypes(include=["bool"]).columns.tolist()
    if bool_cols:
        Xfull[bool_cols] = Xfull[bool_cols].astype("int8")
    return Xfull


def model_feature_names(model) -> Optional[List[str]]:
    names = getattr(model, "feature_name_", None)
    if names is None and hasattr(model, "booster_"):
        try:
            names = list(model.booster_.feature_name())
        except Exception:
            names = None
    return names


st.sidebar.header("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–≥—Ä–µ–≥–∞—Ü–∏–∏")
period = st.sidebar.radio("–ü–µ—Ä–∏–æ–¥", ["–ù–µ–¥–µ–ª—è", "–ú–µ—Å—è—Ü"], index=0)
agg_mode = st.sidebar.radio("–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ", ["–°—É–º–º–∞", "–°—Ä–µ–¥–Ω–µ–µ"], index=0)
metric = st.sidebar.radio("–ú–µ—Ç—Ä–∏–∫–∞", ["MAE", "MAPE"], index=1)
dimension = st.sidebar.radio("–†–∞–∑—Ä–µ–∑", ["–ü–æ –º–∞–≥–∞–∑–∏–Ω–∞–º", "–ü–æ —Å–µ–º–µ–π—Å—Ç–≤–∞–º"], index=0)
back_days = st.sidebar.slider("–î–Ω–µ–π –≤ —Ö–≤–æ—Å—Ç–µ", min_value=28, max_value=180, value=90, step=7)
max_models = st.sidebar.slider("–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª-–≤–æ –º–æ–¥–µ–ª–µ–π", min_value=10, max_value=300, value=100, step=10)

freq = "W" if period == "–ù–µ–¥–µ–ª—è" else "M"
agg_fn = "sum" if agg_mode == "–°—É–º–º–∞" else "mean"
dim_key = "store_nbr" if dimension == "–ü–æ –º–∞–≥–∞–∑–∏–Ω–∞–º" else "family"

models = sorted([p for p in MODELS_DIR.glob("*.joblib") if "__q" not in p.name])
if not models:
    st.warning("–ù–µ—Ç –º–æ–¥–µ–ª–µ–π –≤ –∫–∞—Ç–∞–ª–æ–≥–µ models/. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.")
    st.stop()

Xfull = build_full_features()

# –§–∏–ª—å—Ç—Ä—ã –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º/—Å–µ–º–µ–π—Å—Ç–≤–∞–º
all_stores = sorted(Xfull["store_nbr"].dropna().astype(int).unique().tolist()) if "store_nbr" in Xfull.columns else []
all_fams = sorted(Xfull["family"].dropna().astype(str).unique().tolist()) if "family" in Xfull.columns else []
f1, f2 = st.columns(2)
with f1:
    store_filter = st.multiselect("–§–∏–ª—å—Ç—Ä –º–∞–≥–∞–∑–∏–Ω–æ–≤", options=all_stores, default=[])
with f2:
    family_filter = st.multiselect("–§–∏–ª—å—Ç—Ä —Å–µ–º–µ–π—Å—Ç–≤", options=all_fams, default=[])

progress = st.progress(0)
status = st.empty()

# –ê–∫–∫—É–º—É–ª—è—Ç–æ—Ä—ã –ø–æ (dim, period)
acc = {}
total = min(len(models), max_models)
for i, mp in enumerate(models[:total], start=1):
    try:
        stem = mp.stem
        store_str, fam_str = stem.split("__", 1)
        store = int(store_str)
        fam = fam_str.replace("_", " ")
    except Exception:
        continue

    # –ø—Ä–∏–º–µ–Ω–∏–º —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º –∏ —Å–µ–º–µ–π—Å—Ç–≤–∞–º, –µ—Å–ª–∏ –∑–∞–¥–∞–Ω—ã
    if store_filter and store not in set(store_filter):
        continue
    if family_filter and fam not in set(family_filter):
        continue

    status.text(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –º–æ–¥–µ–ª—å {i}/{total}: ({store}, {fam})")
    try:
        model = joblib.load(mp)
    except Exception:
        continue
    feat_names = model_feature_names(model)
    if not feat_names:
        continue

    df_pair = Xfull[(Xfull["store_nbr"] == store) & (Xfull["family"] == fam)].copy().sort_values("date")
    if df_pair.empty:
        continue
    tail = df_pair.tail(int(back_days)).copy()
    if tail.empty or "sales" not in tail.columns:
        continue
    # –≥–∞—Ä–∞–Ω—Ç–∏—è –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–æ–∫ —Ñ–∏—á
    for f in feat_names:
        if f not in tail.columns:
            tail[f] = 0.0
    X_tail = tail[feat_names]
    try:
        y_pred = model.predict(X_tail)
    except Exception:
        continue

    dfp = pd.DataFrame({
        "date": tail["date"].values,
        "y_true": tail["sales"].values,
        "y_pred": y_pred,
        dim_key: tail[dim_key].values,
    })
    # –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –ø–µ—Ä–∏–æ–¥—É –∏ —Ä–∞–∑—Ä–µ–∑—É
    g = (dfp.set_index("date")
             .groupby([pd.Grouper(freq=freq), dim_key])
             .agg({"y_true": agg_fn, "y_pred": agg_fn})
             .reset_index())

    for _, row in g.iterrows():
        period_key = pd.to_datetime(row["date"]).date()
        dim_val = row[dim_key]
        key = (dim_val, period_key)
        if key not in acc:
            acc[key] = {"y_true": 0.0, "y_pred": 0.0}
        acc[key]["y_true"] += float(row["y_true"]) if agg_fn == "sum" else float(row["y_true"])  # mean —É–∂–µ —É—á—Ç—ë–Ω –Ω–∞ —à–∞–≥–µ –≤—ã—à–µ
        acc[key]["y_pred"] += float(row["y_pred"]) if agg_fn == "sum" else float(row["y_pred"])  # mean —É–∂–µ —É—á—Ç—ë–Ω –Ω–∞ —à–∞–≥–µ –≤—ã—à–µ

    progress.progress(i / total)

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∞–∫–∫—É–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü—É –º–µ—Ç—Ä–∏–∫
if not acc:
    st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∞—Ç–æ–≤.")
    st.stop()

rows = []
for (dim_val, period_key), vals in acc.items():
    y_t = vals["y_true"]
    y_p = vals["y_pred"]
    ae = abs(y_t - y_p)
    me = 0.0 if y_t == 0 else abs((y_t - y_p) / y_t) * 100.0
    rows.append({dim_key: dim_val, "period": period_key, "MAE": ae, "MAPE": me})

dfm = pd.DataFrame(rows)
piv = dfm.pivot_table(index=dim_key, columns="period", values=metric, aggfunc="mean").fillna(0.0)

st.subheader(f"–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞: {metric} ({'—Å—É–º–º–∞' if agg_fn=='sum' else '—Å—Ä–µ–¥–Ω–µ–µ'}) –ø–æ {dimension.lower()} –∏ –ø–µ—Ä–∏–æ–¥–∞–º")
st.caption("–û—Å—å Y ‚Äî %s; –æ—Å—å X ‚Äî %s. –ü–æ–¥—Å–∫–∞–∑–∫–∞: –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–∫—Ä—É—Ç–∫–∞ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤" %
           ("–º–∞–≥–∞–∑–∏–Ω—ã" if dimension=="–ü–æ –º–∞–≥–∞–∑–∏–Ω–∞–º" else "—Å–µ–º–µ–π—Å—Ç–≤–∞", "–Ω–µ–¥–µ–ª–∏" if period=="–ù–µ–¥–µ–ª—è" else "–º–µ—Å—è—Ü—ã"))
st.dataframe(piv.style.background_gradient(cmap="YlOrRd"), use_container_width=True)
st.download_button(
    "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É (CSV)",
    data=piv.to_csv().encode("utf-8"),
    file_name=f"heatmap_{metric}_{'stores' if dimension=='–ü–æ –º–∞–≥–∞–∑–∏–Ω–∞–º' else 'families'}_{'W' if period=='–ù–µ–¥–µ–ª—è' else 'M'}.csv",
    mime="text/csv",
)
