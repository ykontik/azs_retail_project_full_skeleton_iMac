
import json
import os
import sys
from pathlib import Path

import joblib
import numpy as np
import pandas as pd
import requests
import streamlit as st

ROOT = Path(__file__).resolve().parents[1]  # –æ–¥–∏–Ω —É—Ä–æ–≤–µ–Ω—å –≤–≤–µ—Ä—Ö –æ—Ç ui/
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from make_features import make_features

st.set_page_config(page_title="AZS + Retail MVP", layout="wide")
# ---- –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ API_URL –±–µ–∑ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ st.secrets ----
def _resolve_api_url() -> str:
    api = os.getenv("API_URL")
    if api:
        return api
    # —á–∏—Ç–∞–µ–º secrets.toml –≤—Ä—É—á–Ω—É—é, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    candidate_paths = [
        Path.home() / ".streamlit" / "secrets.toml",
        Path.cwd() / ".streamlit" / "secrets.toml",
        Path(__file__).resolve().parents[1] / ".streamlit" / "secrets.toml",  # –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
        Path(__file__).resolve().parent / ".streamlit" / "secrets.toml",      # —Ä—è–¥–æ–º —Å ui/
    ]
    for p in candidate_paths:
        if p.exists():
            try:
                import tomllib  # Python 3.11+
                data = tomllib.loads(p.read_text(encoding="utf-8"))
                return data.get("API_URL", "http://127.0.0.1:8000")
            except Exception:
                pass
    return "http://127.0.0.1:8000"

API_URL = _resolve_api_url()
st.title("‚õΩ AZS + Retail ‚Äî MVP Dashboard")
with st.expander("‚öôÔ∏è –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ API", expanded=False):
    api_url_input = st.text_input("API URL", value=API_URL, help="–ê–¥—Ä–µ—Å FastAPI —Å–µ—Ä–≤–∏—Å–∞")
    if api_url_input:
        API_URL = api_url_input

st.subheader("üìà –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ SKU (MAE / MAPE)")
metrics_path = Path("data_dw/metrics_per_sku.csv")
if metrics_path.exists():
    metrics = pd.read_csv(metrics_path)
    st.dataframe(metrics, use_container_width=True)
    # –∫–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∞—Ç—å CSV
    st.download_button(
        "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å metrics_per_sku.csv",
        data=metrics.to_csv(index=False).encode("utf-8"),
        file_name="metrics_per_sku.csv",
        mime="text/csv",
    )
    # –ø–æ–∫–∞–∑–∞—Ç—å summary_metrics.txt, –µ—Å–ª–∏ –µ—Å—Ç—å
    sum_path = Path("data_dw/summary_metrics.txt")
    if sum_path.exists():
        st.subheader("üìÑ Summary (MAE/MAPE)")
        st.code(sum_path.read_text(encoding="utf-8"))
    # –ê–≥—Ä–µ–≥–∞—Ç—ã –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º/—Å–µ–º–µ–π—Å—Ç–≤–∞–º
    st.subheader("üìä –ê–≥—Ä–µ–≥–∞—Ç—ã –º–µ—Ç—Ä–∏–∫")
    colm, colf = st.columns(2)
    # –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –Ω–æ–º–µ—Ä—É –º–∞–≥–∞–∑–∏–Ω–∞
    with colm:
        st.caption("–°—Ä–µ–¥–Ω–∏–µ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º")
        try:
            agg_store = (metrics.groupby("store_nbr", dropna=True)[["MAE","MAPE_%"]]
                                  .mean()
                                  .round(2)
                                  .reset_index()
                                  .sort_values("MAE"))
            st.dataframe(agg_store, use_container_width=True)
            st.bar_chart(agg_store.set_index("store_nbr")["MAE"], height=160)
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—á–∏—Ç–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ç—ã –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º: {e}")
    # –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —Å–µ–º–µ–π—Å—Ç–≤–∞–º
    with colf:
        st.caption("–°—Ä–µ–¥–Ω–∏–µ –ø–æ —Å–µ–º–µ–π—Å—Ç–≤–∞–º")
        try:
            agg_family = (metrics.groupby("family", dropna=True)[["MAE","MAPE_%"]]
                                  .mean()
                                  .round(2)
                                  .reset_index()
                                  .sort_values("MAE"))
            st.dataframe(agg_family, use_container_width=True)
            st.bar_chart(agg_family.set_index("family")["MAE"], height=160)
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—á–∏—Ç–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ç—ã –ø–æ —Å–µ–º–µ–π—Å—Ç–≤–∞–º: {e}")
else:
    st.info("–§–∞–π–ª metrics_per_sku.csv –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –º–µ—Ç—Ä–∏–∫–∏.")

st.subheader("üß† –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–∏–∑ API)")
available_models_df = None
try:
    r = requests.get(f"{API_URL}/models", timeout=5)
    if r.ok:
        models_json = r.json()["models"]
        models_df = pd.DataFrame(models_json)
        if not models_df.empty:
            available_models_df = models_df.copy()
            store_opts = sorted(models_df["store_nbr"].dropna().astype(int).unique())
            store_sel = st.selectbox("store_nbr", store_opts, index=0, key="store_sel")
            fam_opts = sorted(models_df.loc[models_df["store_nbr"] == store_sel, "family"].dropna().unique().tolist())
            family_sel = st.selectbox("family", fam_opts, index=0, key="family_sel")
        else:
            store_sel = st.number_input("store_nbr", min_value=1, step=1, value=1)
            family_sel = st.text_input("family", value="AUTOMOTIVE")
        st.dataframe(models_df, use_container_width=True)
    else:
        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ API.")
except Exception as e:
    st.warning(f"API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

st.subheader("‚ö° –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥–Ω–æ–∑ (—á–µ—Ä–µ–∑ API)")
col1, col2 = st.columns(2)
with col1:
    store_nbr = st.number_input("store_nbr", min_value=1, step=1, value=1)
    family = st.text_input("family", value="AUTOMOTIVE")
with col2:
    st.caption("–í—Å—Ç–∞–≤—å JSON —Å —Ñ–∏—á–∞–º–∏. –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –±—É–¥—É—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω—ã 0.")
    default_features = {
        "year": 2017, "month": 8, "week": 33, "day": 15, "dayofweek": 2,
        "is_weekend": 0, "is_month_start": 0, "is_month_end": 0,
        "dow_sin": 0.0, "dow_cos": 0.0, "month_sin": 0.0, "month_cos": 0.0,
        "trend": 1600, "is_holiday": 0, "is_christmas": 0, "is_newyear": 0, "is_black_friday": 0,
        "transactions": 500.0, "oil_price": 50.0,
        # –ø—Ä–æ–º–æ-–ø—Ä–∏–∑–Ω–∞–∫–∏ (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∏—Ö –∂–¥—ë—Ç)
        "onpromotion": 0.0,
        "onpromotion_lag_7": 0.0, "onpromotion_lag_14": 0.0, "onpromotion_lag_28": 0.0,
        "onpromotion_rollmean_7": 0.0, "onpromotion_rollstd_7": 0.0,
        "onpromotion_rollmean_30": 0.0, "onpromotion_rollstd_30": 0.0,
        "sales_lag_7": 5.0, "sales_lag_14": 4.0, "sales_lag_28": 6.0,
        "sales_rollmean_7": 5.0, "sales_rollstd_7": 1.2,
        "sales_rollmean_30": 5.3, "sales_rollstd_30": 1.5,
        "cluster": 13
    }
    # –î–µ—Ä–∂–∏–º –±—É—Ñ–µ—Ä —Ç–µ–∫—Å—Ç–∞ —Ñ–∏—á –æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç –∫–ª—é—á–∞ –≤–∏–¥–∂–µ—Ç–∞, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å
    if 'features_text_buf' not in st.session_state:
        st.session_state['features_text_buf'] = json.dumps(default_features, indent=2)
    features_text = st.text_area("features (JSON)", value=st.session_state['features_text_buf'], height=240)
    if features_text != st.session_state['features_text_buf']:
        st.session_state['features_text_buf'] = features_text

    if st.button("–ê–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–∏—Ç—å —Ñ–∏—á–∏ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç–µ", help="–°—á–∏—Ç–∞—Ç—å data_raw/*, —Å–¥–µ–ª–∞—Ç—å make_features –∏ –ø–æ–¥—Å—Ç–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø–∞—Ä—ã"):
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            paths = {k: Path("data_raw")/f"{k}.csv" for k in ["train","transactions","oil","holidays_events","stores"]}
            if not all(p.exists() for p in paths.values()):
                st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ data_raw. –ù—É–∂–Ω—ã: train, transactions, oil, holidays_events, stores")
            else:
                train_df = pd.read_csv(paths["train"], parse_dates=["date"])
                trans_df = pd.read_csv(paths["transactions"], parse_dates=["date"])
                oil_df = pd.read_csv(paths["oil"], parse_dates=["date"])
                hol_df = pd.read_csv(paths["holidays_events"], parse_dates=["date"])
                stores_df = pd.read_csv(paths["stores"])
                Xf, _ = make_features(train_df, hol_df, trans_df, oil_df, stores_df, dropna_target=False)
                mask = (Xf["store_nbr"] == int(store_nbr)) & (Xf["family"] == family)
                sub = Xf.loc[mask].sort_values("date")
                if sub.empty:
                    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–∞–∫–æ–π –ø–∞—Ä—ã store/family.")
                else:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –∑–Ω–∞—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∏—á
                    model_path = Path("models") / f"{int(store_nbr)}__{str(family).replace(' ', '_')}.joblib"
                    if not model_path.exists():
                        st.warning("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –Ω–æ –ø–æ–¥—Å—Ç–∞–≤–ª—é –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∏—á–∏.")
                        feat_names = [c for c in sub.columns if c not in ("id","sales","date")]
                    else:
                        mdl = joblib.load(model_path)
                        feat_names = getattr(mdl, "feature_name_", None)
                        if feat_names is None and hasattr(mdl, "booster_"):
                            try:
                                feat_names = list(mdl.booster_.feature_name())
                            except Exception:
                                feat_names = None
                        if not feat_names:
                            feat_names = [c for c in sub.columns if c not in ("id","sales","date")]
                    # –ì–æ—Ç–æ–≤–∏–º —Å–ª–æ–≤–∞—Ä—å —Ñ–∏—á –¥–ª—è API: —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —Å—Ç—Ä–æ–∫–∏ ‚Üí 0.0
                    last_row = sub.iloc[-1]
                    feats = {}
                    for name in feat_names:
                        val = last_row.get(name, 0.0)
                        try:
                            if isinstance(val, bool):
                                feats[name] = 1.0 if val else 0.0
                            elif isinstance(val, (int, float, np.floating, np.integer)):
                                feats[name] = float(val)
                            else:
                                # —Å—Ç—Ä–æ–∫–æ–≤—ã–µ/–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –∫–æ–¥–∏—Ä—É–µ–º ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º 0.0
                                feats[name] = float(str(val)) if str(val).replace('.', '', 1).isdigit() else 0.0
                        except Exception:
                            feats[name] = 0.0
                    st.session_state['features_text_buf'] = json.dumps(feats, ensure_ascii=False, indent=2)
                    st.success("–§–∏—á–∏ –ø–æ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–æ—Å—Ç—É–ø–Ω–æ–π –¥–∞—Ç—ã.")
                    # –ü–µ—Ä–µ—Ä–∏—Å–æ–≤–∞—Ç—å, —á—Ç–æ–±—ã –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –Ω–æ–≤—ã–µ —Ñ–∏—á–∏ –≤ text_area
                    try:
                        st.experimental_rerun()
                    except Exception:
                        pass
        except Exception as e:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–∏—Ç—å —Ñ–∏—á–∏: {e}")

if st.button("–°–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ API", type="primary"):
    try:
        feats = json.loads(st.session_state.get('features_text_buf', features_text))
        payload = {"store_nbr": int(store_nbr), "family": family, "features": feats}
        r = requests.post(f"{API_URL}/predict_demand", json=payload, timeout=10)
        if r.ok:
            out = r.json()
            st.success(f"–ü—Ä–æ–≥–Ω–æ–∑: {out['pred_qty']:.3f}")
            with st.expander("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏—á–∏"):
                st.code(json.dumps(out["used_features"], ensure_ascii=False, indent=2))
        else:
            st.error(f"–û—à–∏–±–∫–∞ API: {r.status_code} ‚Äî {r.text}")
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞: {e}")

st.markdown("---")
st.subheader("üìâ –ì—Ä–∞—Ñ–∏–∫–∏: –ø—Ä–æ–≥–Ω–æ–∑ vs —Ñ–∞–∫—Ç (–ª–æ–∫–∞–ª—å–Ω—ã–π backtest)")
st.caption("–ù—É–∂–Ω—ã train/transactions/oil/holidays/stores –≤ data_raw/ –∏ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å.")
colA, colB, colC, colD = st.columns(4)
with colA:
    if (available_models_df is not None) and (not available_models_df.empty):
        store_opts_bt = sorted(available_models_df["store_nbr"].dropna().astype(int).unique())
        store_bt = st.selectbox("store_nbr (bt)", store_opts_bt, index=0, key="store_bt_sel")
    else:
        store_bt = st.number_input("store_nbr (bt)", min_value=1, step=1, value=1, key="store_bt")
with colB:
    if (available_models_df is not None) and (not available_models_df.empty):
        fam_opts_bt = sorted(available_models_df.loc[available_models_df["store_nbr"] == int(store_bt), "family"].dropna().unique().tolist())
        if not fam_opts_bt:
            fam_opts_bt = ["AUTOMOTIVE"]
        family_bt = st.selectbox("family (bt)", fam_opts_bt, index=0, key="family_bt_sel")
    else:
        family_bt = st.text_input("family (bt)", value="AUTOMOTIVE", key="family_bt")
with colC:
    back_days = st.number_input("–î–Ω–µ–π –≤ —Ö–≤–æ—Å—Ç–µ", min_value=14, max_value=180, value=60, step=7)
show_xgbps_bt = st.checkbox("–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å XGB per-SKU (–µ—Å–ª–∏ –µ—Å—Ç—å)", value=True)

paths = {k: Path("data_raw")/f"{k}.csv" for k in ["train","transactions","oil","holidays_events","stores"]}
missing = [k for k,p in paths.items() if not p.exists()]
if missing:
    st.warning(f"–ù–µ—Ç —Ñ–∞–π–ª–æ–≤: {', '.join(missing)}")
else:
    model_path = Path("models") / f"{int(store_bt)}__{str(family_bt).replace(' ', '_')}.joblib"
    xgb_ps_path = Path("models") / f"{int(store_bt)}__{str(family_bt).replace(' ', '_')}__xgb.joblib"
    use_catboost_fallback = False
    if not model_path.exists():
        # –§–æ–ª–±—ç–∫: –≥–ª–æ–±–∞–ª—å–Ω–∞—è CatBoost
        cb_path = Path("models") / "global_catboost.cbm"
        if cb_path.exists():
            try:
                from catboost import CatBoostRegressor
                model = CatBoostRegressor()
                model.load_model(str(cb_path))
                use_catboost_fallback = True
                st.info(f"Per-SKU –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ({model_path.name}). –ò—Å–ø–æ–ª—å–∑—É—é –≥–ª–æ–±–∞–ª—å–Ω—É—é CatBoost.")
            except Exception as e:
                st.error(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path} –∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å CatBoost: {e}")
                model = None
        else:
            st.error(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
            model = None
    else:
        model = joblib.load(model_path)
    train_df = pd.read_csv(paths["train"], parse_dates=["date"])
    trans_df = pd.read_csv(paths["transactions"], parse_dates=["date"])
    oil_df = pd.read_csv(paths["oil"], parse_dates=["date"])
    hol_df = pd.read_csv(paths["holidays_events"], parse_dates=["date"])
    stores_df = pd.read_csv(paths["stores"])
    Xfull, yfull = make_features(train_df, hol_df, trans_df, oil_df, stores_df, dropna_target=True)
    for c in ["store_nbr","family","type","city","state","cluster","is_holiday"]:
        if c in Xfull.columns:
            Xfull[c] = Xfull[c].astype("category")
    mask_pair = (Xfull["store_nbr"] == int(store_bt)) & (Xfull["family"] == family_bt)
    df_pair = Xfull.loc[mask_pair].copy().sort_values("date")
    if df_pair.empty:
        st.error("–î–ª—è —ç—Ç–æ–π –ø–∞—Ä—ã –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
    else:
        feat_names = getattr(model, "feature_name_", None)
        if feat_names is None and hasattr(model, "booster_"):
            try: feat_names = list(model.booster_.feature_name())
            except: feat_names = None
            # –î–ª—è CatBoost —Ñ–æ–ª–±—ç–∫–∞ –ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∏—á –∏–∑ metrics_global_catboost.json
            if use_catboost_fallback and (feat_names is None):
                cb_feat = None
                meta_path = Path("data_dw") / "metrics_global_catboost.json"
                if meta_path.exists():
                    try:
                        cb_feat = json.loads(meta_path.read_text(encoding="utf-8")).get("features")
                    except Exception:
                        cb_feat = None
                feat_names = cb_feat or [c for c in df_pair.columns if c not in ("id","sales","date") and not np.issubdtype(df_pair[c].dtype, np.datetime64)]

            if feat_names is None:
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∏—á –º–æ–¥–µ–ª–∏.")
            else:
                for f in feat_names:
                    if f not in df_pair.columns: df_pair[f] = 0.0
                tail = df_pair.tail(int(back_days)).copy()
                X_tail = tail[feat_names]; y_tail = tail["sales"].values
                # –ü—Ä–æ–≥–Ω–æ–∑ –±–∞–∑–æ–≤–æ–π (point) –º–æ–¥–µ–ª–∏ –∏–ª–∏ CatBoost
                try:
                    y_pred = model.predict(X_tail)
                except Exception:
                    # CatBoost –º–æ–∂–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å Pool, –Ω–æ predict –ø–æ DataFrame —Ç–æ–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç; fallback –Ω–∞ numpy
                    y_pred = model.predict(X_tail.values)

                # –ü–æ–ø—Ä–æ–±—É–µ–º —Ç–∞–∫–∂–µ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –ª–∏–Ω–∏—é XGBoost per-SKU, –µ—Å–ª–∏ –µ—Å—Ç—å –º–æ–¥–µ–ª—å
                y_pred_xgb = None
                if xgb_ps_path.exists():
                    try:
                        mdl_xgb_ps = joblib.load(xgb_ps_path)
                        feat_xps = getattr(mdl_xgb_ps, 'feature_names_in_', None)
                        cols_xps = list(feat_xps) if feat_xps is not None else feat_names
                        for f in cols_xps:
                            if f not in tail.columns:
                                tail[f] = 0.0
                        X_tail_xps = tail[cols_xps]
                        y_pred_xgb = mdl_xgb_ps.predict(X_tail_xps)
                    except Exception:
                        y_pred_xgb = None
                # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ P50 –∏ P90 –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∫–æ—Ä–∏–¥–æ—Ä–∞
                q50_path = Path("models") / f"{int(store_bt)}__{str(family_bt).replace(' ', '_')}__q50.joblib"
                q90_path = Path("models") / f"{int(store_bt)}__{str(family_bt).replace(' ', '_')}__q90.joblib"
                q50_pred = q90_pred = None
                if not use_catboost_fallback:  # –∫–≤–∞–Ω—Ç–∏–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —É per-SKU –º–æ–¥–µ–ª–µ–π
                    try:
                        if q50_path.exists():
                            mdl_q50 = joblib.load(q50_path)
                            q50_pred = mdl_q50.predict(X_tail)
                        if q90_path.exists():
                            mdl_q90 = joblib.load(q90_path)
                            q90_pred = mdl_q90.predict(X_tail)
                    except Exception as e:
                        st.warning(f"–ö–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å: {e}")
                import matplotlib.pyplot as plt
                # –í–∫–ª–∞–¥–∫–∞ —Å –≥—Ä–∞—Ñ–∏–∫–æ–º –ø–æ –¥–Ω—è–º –∏ –≤–∫–ª–∞–¥–∫–∞ —Å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                tabs = st.tabs(["–ü–æ –¥–Ω—è–º", "–ê–≥—Ä–µ–≥–∞—Ü–∏–∏ (–Ω–µ–¥–µ–ª–∏/–º–µ—Å—è—Ü—ã)"])

                # –í–∫–ª–∞–¥–∫–∞ 1: –ü–æ –¥–Ω—è–º
                with tabs[0]:
                    fig1 = plt.figure(figsize=(12,4))
                    plt.plot(tail["date"], y_tail, label="–§–∞–∫—Ç")
                    plt.plot(tail["date"], y_pred, label="–ü—Ä–æ–≥–Ω–æ–∑ (LGBM/CatBoost)")
                    if y_pred_xgb is not None and show_xgbps_bt:
                        plt.plot(tail["date"], y_pred_xgb, label="XGBoost per-SKU")
                    # –ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã ‚Äî —Ä–∏—Å—É–µ–º –∫–æ—Ä–∏–¥–æ—Ä
                    if q50_pred is not None and q90_pred is not None:
                        plt.fill_between(tail["date"], q50_pred, q90_pred, color="orange", alpha=0.25, label="P50‚ÄìP90")
                    title = "–ü—Ä–æ–¥–∞–∂–∏: —Ñ–∞–∫—Ç vs –ø—Ä–æ–≥–Ω–æ–∑"
                    if 'use_catboost_fallback' in locals() and use_catboost_fallback:
                        title += " ‚Äî CatBoost fallback"
                        # –í–∏–∑—É–∞–ª—å–Ω–∞—è –ø–æ–º–µ—Ç–∫–∞ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ
                        plt.text(0.01, 0.98, "CatBoost fallback", transform=plt.gca().transAxes,
                                 fontsize=10, va='top', ha='left', color='white',
                                 bbox=dict(facecolor='#6c757d', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.3'))
                    plt.title(title); plt.xlabel("–î–∞—Ç–∞"); plt.ylabel("–ü—Ä–æ–¥–∞–∂–∏")
                    plt.legend(); plt.grid()
                    st.pyplot(fig1)
                mae = np.mean(np.abs(y_tail - y_pred))
                denom = np.where(y_tail == 0, 1, y_tail)
                mape = np.mean(np.abs((y_tail - y_pred) / denom)) * 100.0
                st.metric("MAE (tail)", f"{mae:.3f} —à—Ç.")
                st.metric("MAPE (tail, %)", f"{mape:.2f}%")
                if y_pred_xgb is not None and show_xgbps_bt:
                        mae_xgb = np.mean(np.abs(y_tail - y_pred_xgb))
                        mape_xgb = np.mean(np.abs((y_tail - y_pred_xgb) / denom)) * 100.0
                        st.metric("MAE XGBoost (tail)", f"{mae_xgb:.3f} —à—Ç.")
                        st.metric("MAPE XGBoost (tail, %)", f"{mape_xgb:.2f}%")
                # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–≤–∞–Ω—Ç–∏–ª—å–Ω–æ–≥–æ –∫–æ—Ä–∏–¥–æ—Ä–∞ (–ø–æ –¥–Ω—è–º), –µ—Å–ª–∏ –µ—Å—Ç—å
                if q50_pred is not None and q90_pred is not None:
                    # –¥–æ–ª—è —Ç–æ—á–µ–∫ —Ñ–∞–∫—Ç–∞ –≤–Ω—É—Ç—Ä–∏ [P50, P90]
                    inside = np.mean((y_tail >= np.minimum(q50_pred, q90_pred)) & (y_tail <= np.maximum(q50_pred, q90_pred)))
                    avg_width = float(np.mean(np.abs(q90_pred - q50_pred)))
                    st.metric("–î–æ–ª—è –ø–æ–∫—Ä—ã—Ç–∏—è —Ñ–∞–∫—Ç–∞ (P50‚ÄìP90)", f"{inside*100:.1f}%")
                    st.metric("–°—Ä–µ–¥–Ω—è—è —à–∏—Ä–∏–Ω–∞ –∫–æ—Ä–∏–¥–æ—Ä–∞", f"{avg_width:.3f} —à—Ç.")

                # –í–∫–ª–∞–¥–∫–∞ 2: –ê–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–µ–¥–µ–ª–∏/–º–µ—Å—è—Ü—ã)
                with tabs[1]:
                    st.caption("–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –ø–µ—Ä–∏–æ–¥—É (—Å—É–º–º–∞ –ø–æ –¥–Ω—è–º)")
                    period = st.radio("–ü–µ—Ä–∏–æ–¥", ["–ù–µ–¥–µ–ª—è", "–ú–µ—Å—è—Ü"], horizontal=True)
                    agg_mode = st.radio("–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ", ["–°—É–º–º–∞", "–°—Ä–µ–¥–Ω–µ–µ"], horizontal=True)
                    freq = "W" if period == "–ù–µ–¥–µ–ª—è" else "M"
                    # –ì–æ—Ç–æ–≤–∏–º DataFrame –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
                    df_plot = pd.DataFrame({
                        "date": tail["date"].values,
                        "y_true": y_tail,
                        "y_pred": y_pred,
                    })
                    if q50_pred is not None and q90_pred is not None:
                        df_plot["p50"] = q50_pred
                        df_plot["p90"] = q90_pred
                    # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—É–º–º–æ–π –ø–æ –ø–µ—Ä–∏–æ–¥—É
                    grouped = df_plot.set_index("date").groupby(pd.Grouper(freq=freq))
                    if agg_mode == "–°—É–º–º–∞":
                        g = grouped.sum().reset_index()
                    else:
                        g = grouped.mean().reset_index()
                    # –ì—Ä–∞—Ñ–∏–∫ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
                    fig2 = plt.figure(figsize=(12,4))
                    plt.plot(g["date"], g["y_true"], label="–§–∞–∫—Ç (agg)")
                    plt.plot(g["date"], g["y_pred"], label="–ü—Ä–æ–≥–Ω–æ–∑ (agg)")
                    if y_pred_xgb is not None and show_xgbps_bt:
                        # –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º XGB –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –ø–µ—Ä–∏–æ–¥—É
                        g_x = (pd.DataFrame({"date": tail["date"].values, "y": y_pred_xgb})
                                 .set_index("date").groupby(pd.Grouper(freq=freq)).sum().reset_index())
                        plt.plot(g_x["date"], g_x["y"], label="XGBoost per-SKU (agg)")
                    if "p50" in g.columns and "p90" in g.columns:
                        plt.fill_between(g["date"], g["p50"], g["p90"], color="orange", alpha=0.25, label="P50‚ÄìP90 (agg)")
                    ylabel = "–ü—Ä–æ–¥–∞–∂–∏ (—Å—É–º–º–∞)" if agg_mode == "–°—É–º–º–∞" else "–ü—Ä–æ–¥–∞–∂–∏ (—Å—Ä–µ–¥–Ω–µ–µ)"
                    agg_title = f"–ê–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏: {period.lower()}"
                    if 'use_catboost_fallback' in locals() and use_catboost_fallback:
                        agg_title += " ‚Äî CatBoost fallback"
                        plt.text(0.01, 0.98, "CatBoost fallback", transform=plt.gca().transAxes,
                                 fontsize=10, va='top', ha='left', color='white',
                                 bbox=dict(facecolor='#6c757d', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.3'))
                    plt.title(agg_title); plt.xlabel("–ü–µ—Ä–∏–æ–¥"); plt.ylabel(ylabel)
                    plt.legend(); plt.grid()
                    st.pyplot(fig2)

                    # –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ä—è–¥—É
                    y_true_agg = g["y_true"].values
                    y_pred_agg = g["y_pred"].values
                    mae_agg = np.mean(np.abs(y_true_agg - y_pred_agg))
                    denom_agg = np.where(y_true_agg == 0, 1, y_true_agg)
                    mape_agg = np.mean(np.abs((y_true_agg - y_pred_agg) / denom_agg)) * 100.0
                    st.metric("MAE (agg)", f"{mae_agg:.3f} —à—Ç.")
                    st.metric("MAPE (agg, %)", f"{mape_agg:.2f}%")

st.markdown("---")
st.subheader("üîç –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (feature importance)")

colF1, colF2 = st.columns(2)
with colF1:
    store_imp = st.number_input("store_nbr (FI)", min_value=1, step=1, value=int(store_bt))
with colF2:
    family_imp = st.text_input("family (FI)", value=family_bt)

imp_path = Path("models") / f"{int(store_imp)}__{str(family_imp).replace(' ', '_')}.joblib"
if not imp_path.exists():
    st.info(f"–ù–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è FI: {imp_path.name}")
else:
    try:
        mdl = joblib.load(imp_path)
        # –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ —Ñ–∏—á –∏ –∏—Ö –≤–∞–∂–Ω–æ—Å—Ç–∏ (gain)
        if hasattr(mdl, "booster_"):
            names = list(mdl.booster_.feature_name())
            gains = mdl.booster_.feature_importance(importance_type="gain")
        else:
            # fallback: –µ—Å–ª–∏ –Ω–µ—Ç booster_ (—Ä–µ–¥–∫–æ)
            names = getattr(mdl, "feature_name_", [])
            gains = getattr(mdl, "feature_importances_", [])
        import pandas as pd
        df_fi = pd.DataFrame({"feature": names, "gain": gains}).sort_values("gain", ascending=False).head(15)
        st.dataframe(df_fi, use_container_width=True)
        st.bar_chart(df_fi.set_index("feature"))
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç–∏: {e}")

st.markdown("---")

# ----------------------- –ë–∏–∑–Ω–µ—Å: ROP / Safety Stock -----------------------
st.subheader("üì¶ –†–∞—Å—á—ë—Ç ROP / Safety Stock")
colp1, colp2 = st.columns(2)
with colp1:
    lead_time_days = st.number_input("Lead time (–¥–Ω–µ–π)", min_value=1, value=2, step=1, key="lead_time_days")
    service_level = st.slider("–£—Ä–æ–≤–µ–Ω—å —Å–µ—Ä–≤–∏—Å–∞", min_value=0.80, max_value=0.99, value=0.95, step=0.01, key="service_level")
    calc = st.button("–†–∞—Å—Å—á–∏—Ç–∞—Ç—å ROP/SS", key="calc_rop")
with colp2:
    st.caption("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ P50/P90, –µ—Å–ª–∏ –æ–±—É—á–µ–Ω—ã. –ò–Ω–∞—á–µ ‚Äî —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ œÉ ‚âà 0.25¬∑mean.")

if 'features_text_buf' in st.session_state and st.session_state.get('features_text_buf') and st.session_state.get('calc_rop'):
    try:
        feats_body = json.loads(st.session_state['features_text_buf'])
        body = {
            "store_nbr": int(store_nbr),
            "family": str(family),
            "features": feats_body,
            "lead_time_days": int(st.session_state.get('lead_time_days', 2)),
            "service_level": float(st.session_state.get('service_level', 0.95)),
        }
        r = requests.post(f"{API_URL}/reorder_point", json=body, timeout=10)
        if r.ok:
            data = r.json()
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("Daily mean (API), —à—Ç.", f"{data['daily_mean']:.2f}")
            m2.metric("Sigma (API), —à—Ç.", f"{data['sigma_daily']:.2f}")
            m3.metric("Safety Stock (API), —à—Ç.", f"{data['safety_stock']:.2f}")
            m4.metric("ROP (API), —à—Ç.", f"{data['reorder_point']:.2f}")
            st.caption(f"quantiles_used={data.get('quantiles_used', False)} | z={data.get('service_level_z')}")
        else:
            st.error(f"–û—à–∏–±–∫–∞ API: {r.status_code} {r.text}")
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞: {e}")

# ----------------------- –ü–ª–∞–Ω –∑–∞–ø–∞—Å–æ–≤ (–æ—Ñ–ª–∞–π–Ω —Å–∫—Ä–∏–ø—Ç) -----------------------
st.subheader("üì¶ –ü–ª–∞–Ω –∑–∞–ø–∞—Å–æ–≤ (–±–µ–π—Å–ª–∞–π–Ω –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–æ–¥–∞–∂)")
stock_csv = Path("data_dw/stock_plan.csv")
if stock_csv.exists():
    try:
        df_stock = pd.read_csv(stock_csv)
        st.dataframe(df_stock, use_container_width=True)
        st.download_button(
            "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å stock_plan.csv",
            data=df_stock.to_csv(index=False).encode("utf-8"),
            file_name="stock_plan.csv",
            mime="text/csv",
        )
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å stock_plan.csv: {e}")
else:
    st.info("–§–∞–π–ª stock_plan.csv –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å—Ç–∏: make stock")

# ----------------------- SHAP –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä -----------------------
st.subheader("üîç SHAP ‚Äî –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä)")
try:
    store_cur = int(store_nbr)
    family_cur = str(family)
except Exception:
    store_cur, family_cur = 1, "AUTOMOTIVE"
shap_png = Path("data_dw") / f"shap_summary_{store_cur}__{family_cur}.png"
shap_csv = Path("data_dw") / f"shap_top_{store_cur}__{family_cur}.csv"
cols_sh = st.columns(2)
with cols_sh[0]:
    if shap_png.exists():
        st.image(str(shap_png), caption=shap_png.name, use_column_width=True)
    else:
        st.info("SHAP –∫–∞—Ä—Ç–∏–Ω–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —á–µ—Ä–µ–∑ scripts/shap_report.py")
with cols_sh[1]:
    if shap_csv.exists():
        df_shap = pd.read_csv(shap_csv)
        st.dataframe(df_shap.head(25), use_container_width=True)
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å shap_top.csv", data=df_shap.to_csv(index=False).encode('utf-8'), file_name=shap_csv.name, mime='text/csv')
    else:
        st.info("–¢–∞–±–ª–∏—Ü–∞ SHAP –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")

st.subheader("üìÇ –ü—Ä–æ—Å–º–æ—Ç—Ä data_raw (–ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏)")
raw_dir = Path("data_raw")
if not raw_dir.exists():
    st.info("–ü–∞–ø–∫–∞ data_raw –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–æ–∑–¥–∞–π –∏ –ø–æ–ª–æ–∂–∏ CSV: train.csv, transactions.csv, oil.csv, holidays_events.csv, stores.csv")
else:
    cols = st.columns(5)
    files = ["train.csv", "transactions.csv", "oil.csv", "holidays_events.csv", "stores.csv"]
    for i, fname in enumerate(files):
        p = raw_dir / fname
        with cols[i]:
            st.write(f"**{fname}**")
            if p.exists():
                try:
                    df = pd.read_csv(p, nrows=5)
                    st.dataframe(df, use_container_width=True)
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {e}")
            else:
                st.warning("–ù–µ—Ç —Ñ–∞–π–ª–∞")
