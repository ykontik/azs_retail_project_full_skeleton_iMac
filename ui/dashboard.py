
import json
import os
import sys
from pathlib import Path

import joblib
import numpy as np
import pandas as pd
import requests
import streamlit as st

ROOT = Path(__file__).resolve().parents[1]  # Ğ¾Ğ´Ğ¸Ğ½ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ²Ğ²ĞµÑ€Ñ… Ğ¾Ñ‚ ui/
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from make_features import make_features

st.set_page_config(page_title="AZS + Retail MVP", layout="wide")
# ---- Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ API_URL Ğ±ĞµĞ· Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğº st.secrets ----
def _resolve_api_url() -> str:
    api = os.getenv("API_URL")
    if api:
        return api
    # Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ secrets.toml Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ, Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ¾Ğ½ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚
    candidate_paths = [
        Path.home() / ".streamlit" / "secrets.toml",
        Path.cwd() / ".streamlit" / "secrets.toml",
        Path(__file__).resolve().parents[1] / ".streamlit" / "secrets.toml",  # ĞºĞ¾Ñ€ĞµĞ½ÑŒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
        Path(__file__).resolve().parent / ".streamlit" / "secrets.toml",      # Ñ€ÑĞ´Ğ¾Ğ¼ Ñ ui/
    ]
    for p in candidate_paths:
        if p.exists():
            try:
                import tomllib  # Python 3.11+
                data = tomllib.loads(p.read_text(encoding="utf-8"))
                return data.get("API_URL", "http://127.0.0.1:8000")
            except Exception:
                pass
    return "http://127.0.0.1:8000"

API_URL = _resolve_api_url()
st.title("â›½ AZS + Retail â€” MVP Dashboard")
with st.expander("âš™ï¸ ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº API", expanded=False):
    api_url_input = st.text_input("API URL", value=API_URL, help="ĞĞ´Ñ€ĞµÑ FastAPI ÑĞµÑ€Ğ²Ğ¸ÑĞ°")
    if api_url_input:
        API_URL = api_url_input

st.subheader("ğŸ“ˆ ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ğ¾ SKU (MAE / MAPE)")
metrics_path = Path("data_dw/metrics_per_sku.csv")
if metrics_path.exists():
    metrics = pd.read_csv(metrics_path)
    st.dataframe(metrics, use_container_width=True)
    # ĞºĞ½Ğ¾Ğ¿ĞºĞ° ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ CSV
    st.download_button(
        "â¬‡ï¸ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ metrics_per_sku.csv",
        data=metrics.to_csv(index=False).encode("utf-8"),
        file_name="metrics_per_sku.csv",
        mime="text/csv",
    )
    # Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ summary_metrics.txt, ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
    sum_path = Path("data_dw/summary_metrics.txt")
    if sum_path.exists():
        st.subheader("ğŸ“„ Summary (MAE/MAPE)")
        st.code(sum_path.read_text(encoding="utf-8"))
    # ĞĞ³Ñ€ĞµĞ³Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½Ğ°Ğ¼/ÑĞµĞ¼ĞµĞ¹ÑÑ‚Ğ²Ğ°Ğ¼
    st.subheader("ğŸ“Š ĞĞ³Ñ€ĞµĞ³Ğ°Ñ‚Ñ‹ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº")
    colm, colf = st.columns(2)
    # Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ½Ğ¾Ğ¼ĞµÑ€Ñƒ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½Ğ°
    with colm:
        st.caption("Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½Ğ°Ğ¼")
        try:
            agg_store = (metrics.groupby("store_nbr", dropna=True)[["MAE","MAPE_%"]]
                                  .mean()
                                  .round(2)
                                  .reset_index()
                                  .sort_values("MAE"))
            st.dataframe(agg_store, use_container_width=True)
            st.bar_chart(agg_store.set_index("store_nbr")["MAE"], height=160)
        except Exception as e:
            st.warning(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾ÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½Ğ°Ğ¼: {e}")
    # Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ ÑĞµĞ¼ĞµĞ¹ÑÑ‚Ğ²Ğ°Ğ¼
    with colf:
        st.caption("Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğµ Ğ¿Ğ¾ ÑĞµĞ¼ĞµĞ¹ÑÑ‚Ğ²Ğ°Ğ¼")
        try:
            agg_family = (metrics.groupby("family", dropna=True)[["MAE","MAPE_%"]]
                                  .mean()
                                  .round(2)
                                  .reset_index()
                                  .sort_values("MAE"))
            st.dataframe(agg_family, use_container_width=True)
            st.bar_chart(agg_family.set_index("family")["MAE"], height=160)
        except Exception as e:
            st.warning(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾ÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ ÑĞµĞ¼ĞµĞ¹ÑÑ‚Ğ²Ğ°Ğ¼: {e}")
else:
    st.info("Ğ¤Ğ°Ğ¹Ğ» metrics_per_sku.csv Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑƒĞ²Ğ¸Ğ´ĞµÑ‚ÑŒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸.")

st.subheader("ğŸ§  Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (Ğ¸Ğ· API)")
available_models_df = None
try:
    r = requests.get(f"{API_URL}/models", timeout=5)
    if r.ok:
        models_json = r.json()["models"]
        models_df = pd.DataFrame(models_json)
        if not models_df.empty:
            available_models_df = models_df.copy()
            store_opts = sorted(models_df["store_nbr"].dropna().astype(int).unique())
            store_sel = st.selectbox("store_nbr", store_opts, index=0, key="store_sel")
            fam_opts = sorted(models_df.loc[models_df["store_nbr"] == store_sel, "family"].dropna().unique().tolist())
            family_sel = st.selectbox("family", fam_opts, index=0, key="family_sel")
        else:
            store_sel = st.number_input("store_nbr", min_value=1, step=1, value=1)
            family_sel = st.text_input("family", value="AUTOMOTIVE")
        st.dataframe(models_df, use_container_width=True)
    else:
        st.warning("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸Ğ· API.")
except Exception as e:
    st.warning(f"API Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: {e}")

st.subheader("âš¡ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· (Ñ‡ĞµÑ€ĞµĞ· API)")
col1, col2 = st.columns(2)
with col1:
    store_nbr = st.number_input("store_nbr", min_value=1, step=1, value=1)
    family = st.text_input("family", value="AUTOMOTIVE")
with col2:
    st.caption("Ğ’ÑÑ‚Ğ°Ğ²ÑŒ JSON Ñ Ñ„Ğ¸Ñ‡Ğ°Ğ¼Ğ¸. ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ñ‹ 0.")
    default_features = {
        "year": 2017, "month": 8, "week": 33, "day": 15, "dayofweek": 2,
        "is_weekend": 0, "is_month_start": 0, "is_month_end": 0,
        "dow_sin": 0.0, "dow_cos": 0.0, "month_sin": 0.0, "month_cos": 0.0,
        "trend": 1600, "is_holiday": 0, "is_christmas": 0, "is_newyear": 0, "is_black_friday": 0,
        "transactions": 500.0, "oil_price": 50.0,
        # Ğ¿Ñ€Ğ¾Ğ¼Ğ¾-Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ (ĞµÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¸Ñ… Ğ¶Ğ´Ñ‘Ñ‚)
        "onpromotion": 0.0,
        "onpromotion_lag_7": 0.0, "onpromotion_lag_14": 0.0, "onpromotion_lag_28": 0.0,
        "onpromotion_rollmean_7": 0.0, "onpromotion_rollstd_7": 0.0,
        "onpromotion_rollmean_30": 0.0, "onpromotion_rollstd_30": 0.0,
        "sales_lag_7": 5.0, "sales_lag_14": 4.0, "sales_lag_28": 6.0,
        "sales_rollmean_7": 5.0, "sales_rollstd_7": 1.2,
        "sales_rollmean_30": 5.3, "sales_rollstd_30": 1.5,
        "cluster": 13
    }
    # Ğ”ĞµÑ€Ğ¶Ğ¸Ğ¼ Ğ±ÑƒÑ„ĞµÑ€ Ñ‚ĞµĞºÑÑ‚Ğ° Ñ„Ğ¸Ñ‡ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾ Ğ¾Ñ‚ ĞºĞ»ÑÑ‡Ğ° Ğ²Ğ¸Ğ´Ğ¶ĞµÑ‚Ğ°, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑÑ‚ÑŒ
    if 'features_text_buf' not in st.session_state:
        st.session_state['features_text_buf'] = json.dumps(default_features, indent=2)
    features_text = st.text_area("features (JSON)", value=st.session_state['features_text_buf'], height=240)
    if features_text != st.session_state['features_text_buf']:
        st.session_state['features_text_buf'] = features_text

    if st.button("ĞĞ²Ñ‚Ğ¾Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ñ„Ğ¸Ñ‡Ğ¸ Ğ¿Ğ¾ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¹ Ğ´Ğ°Ñ‚Ğµ", help="Ğ¡Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ data_raw/*, ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ make_features Ğ¸ Ğ¿Ğ¾Ğ´ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€Ñ‹"):
        try:
            # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
            paths = {k: Path("data_raw")/f"{k}.csv" for k in ["train","transactions","oil","holidays_events","stores"]}
            if not all(p.exists() for p in paths.values()):
                st.warning("ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ²ÑĞµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ¸Ğ· data_raw. ĞÑƒĞ¶Ğ½Ñ‹: train, transactions, oil, holidays_events, stores")
            else:
                train_df = pd.read_csv(paths["train"], parse_dates=["date"])
                trans_df = pd.read_csv(paths["transactions"], parse_dates=["date"])
                oil_df = pd.read_csv(paths["oil"], parse_dates=["date"])
                hol_df = pd.read_csv(paths["holidays_events"], parse_dates=["date"])
                stores_df = pd.read_csv(paths["stores"])
                Xf, _ = make_features(train_df, hol_df, trans_df, oil_df, stores_df, dropna_target=False)
                mask = (Xf["store_nbr"] == int(store_nbr)) & (Xf["family"] == family)
                sub = Xf.loc[mask].sort_values("date")
                if sub.empty:
                    st.warning("ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ñ‚Ğ°ĞºĞ¾Ğ¹ Ğ¿Ğ°Ñ€Ñ‹ store/family.")
                else:
                    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ·Ğ½Ğ°Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ„Ğ¸Ñ‡
                    model_path = Path("models") / f"{int(store_nbr)}__{str(family).replace(' ', '_')}.joblib"
                    if not model_path.exists():
                        st.warning("ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°, Ğ½Ğ¾ Ğ¿Ğ¾Ğ´ÑÑ‚Ğ°Ğ²Ğ»Ñ Ğ²ÑĞµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ñ„Ğ¸Ñ‡Ğ¸.")
                        feat_names = [c for c in sub.columns if c not in ("id","sales","date")]
                    else:
                        mdl = joblib.load(model_path)
                        feat_names = getattr(mdl, "feature_name_", None)
                        if feat_names is None and hasattr(mdl, "booster_"):
                            try:
                                feat_names = list(mdl.booster_.feature_name())
                            except Exception:
                                feat_names = None
                        if not feat_names:
                            feat_names = [c for c in sub.columns if c not in ("id","sales","date")]
                    # Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ñ„Ğ¸Ñ‡ Ğ´Ğ»Ñ API: Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ, ÑÑ‚Ñ€Ğ¾ĞºĞ¸ â†’ 0.0
                    last_row = sub.iloc[-1]
                    feats = {}
                    for name in feat_names:
                        val = last_row.get(name, 0.0)
                        try:
                            if isinstance(val, bool):
                                feats[name] = 1.0 if val else 0.0
                            elif isinstance(val, (int, float, np.floating, np.integer)):
                                feats[name] = float(val)
                            else:
                                # ÑÑ‚Ñ€Ğ¾ĞºĞ¾Ğ²Ñ‹Ğµ/ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ½Ğµ ĞºĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ â€” Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ 0.0
                                feats[name] = float(str(val)) if str(val).replace('.', '', 1).isdigit() else 0.0
                        except Exception:
                            feats[name] = 0.0
                    st.session_state['features_text_buf'] = json.dumps(feats, ensure_ascii=False, indent=2)
                    st.success("Ğ¤Ğ¸Ñ‡Ğ¸ Ğ¿Ğ¾Ğ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ğ¸Ğ· Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾Ğ¹ Ğ´Ğ°Ñ‚Ñ‹.")
                    # ĞŸĞµÑ€ĞµÑ€Ğ¸ÑĞ¾Ğ²Ğ°Ñ‚ÑŒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ñ„Ğ¸Ñ‡Ğ¸ Ğ² text_area
                    try:
                        st.experimental_rerun()
                    except Exception:
                        pass
        except Exception as e:
            st.error(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ñ„Ğ¸Ñ‡Ğ¸: {e}")

if st.button("Ğ¡Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· API", type="primary"):
    try:
        feats = json.loads(st.session_state.get('features_text_buf', features_text))
        payload = {"store_nbr": int(store_nbr), "family": family, "features": feats}
        r = requests.post(f"{API_URL}/predict_demand", json=payload, timeout=10)
        if r.ok:
            out = r.json()
            st.success(f"ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ·: {out['pred_qty']:.3f}")
            with st.expander("Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ„Ğ¸Ñ‡Ğ¸"):
                st.code(json.dumps(out["used_features"], ensure_ascii=False, indent=2))
        else:
            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° API: {r.status_code} â€” {r.text}")
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")

st.markdown("---")
st.subheader("ğŸ“‰ Ğ“Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸: Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· vs Ñ„Ğ°ĞºÑ‚ (Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ backtest)")
st.caption("ĞÑƒĞ¶Ğ½Ñ‹ train/transactions/oil/holidays/stores Ğ² data_raw/ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ.")
colA, colB, colC, colD = st.columns(4)
with colA:
    if (available_models_df is not None) and (not available_models_df.empty):
        store_opts_bt = sorted(available_models_df["store_nbr"].dropna().astype(int).unique())
        store_bt = st.selectbox("store_nbr (bt)", store_opts_bt, index=0, key="store_bt_sel")
    else:
        store_bt = st.number_input("store_nbr (bt)", min_value=1, step=1, value=1, key="store_bt")
with colB:
    if (available_models_df is not None) and (not available_models_df.empty):
        fam_opts_bt = sorted(available_models_df.loc[available_models_df["store_nbr"] == int(store_bt), "family"].dropna().unique().tolist())
        if not fam_opts_bt:
            fam_opts_bt = ["AUTOMOTIVE"]
        family_bt = st.selectbox("family (bt)", fam_opts_bt, index=0, key="family_bt_sel")
    else:
        family_bt = st.text_input("family (bt)", value="AUTOMOTIVE", key="family_bt")
with colC:
    back_days = st.number_input("Ğ”Ğ½ĞµĞ¹ Ğ² Ñ…Ğ²Ğ¾ÑÑ‚Ğµ", min_value=14, max_value=180, value=60, step=7)
show_xgbps_bt = st.checkbox("ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ XGB per-SKU (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)", value=True)

paths = {k: Path("data_raw")/f"{k}.csv" for k in ["train","transactions","oil","holidays_events","stores"]}
missing = [k for k,p in paths.items() if not p.exists()]
if missing:
    st.warning(f"ĞĞµÑ‚ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²: {', '.join(missing)}")
else:
    model_path = Path("models") / f"{int(store_bt)}__{str(family_bt).replace(' ', '_')}.joblib"
    xgb_ps_path = Path("models") / f"{int(store_bt)}__{str(family_bt).replace(' ', '_')}__xgb.joblib"
    use_catboost_fallback = False
    if not model_path.exists():
        # Ğ¤Ğ¾Ğ»Ğ±ÑĞº: Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ°Ñ CatBoost
        cb_path = Path("models") / "global_catboost.cbm"
        if cb_path.exists():
            try:
                from catboost import CatBoostRegressor
                model = CatBoostRegressor()
                model.load_model(str(cb_path))
                use_catboost_fallback = True
                st.info(f"Per-SKU Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° ({model_path.name}). Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½ÑƒÑ CatBoost.")
            except Exception as e:
                st.error(f"ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: {model_path} Ğ¸ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ CatBoost: {e}")
                model = None
        else:
            st.error(f"ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: {model_path}")
            model = None
    else:
        model = joblib.load(model_path)
    train_df = pd.read_csv(paths["train"], parse_dates=["date"])
    trans_df = pd.read_csv(paths["transactions"], parse_dates=["date"])
    oil_df = pd.read_csv(paths["oil"], parse_dates=["date"])
    hol_df = pd.read_csv(paths["holidays_events"], parse_dates=["date"])
    stores_df = pd.read_csv(paths["stores"])
    Xfull, yfull = make_features(train_df, hol_df, trans_df, oil_df, stores_df, dropna_target=True)
    for c in ["store_nbr","family","type","city","state","cluster","is_holiday"]:
        if c in Xfull.columns:
            Xfull[c] = Xfull[c].astype("category")
    mask_pair = (Xfull["store_nbr"] == int(store_bt)) & (Xfull["family"] == family_bt)
    df_pair = Xfull.loc[mask_pair].copy().sort_values("date")
    if df_pair.empty:
        st.error("Ğ”Ğ»Ñ ÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ°Ñ€Ñ‹ Ğ½ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….")
    else:
        feat_names = getattr(model, "feature_name_", None)
        if feat_names is None and hasattr(model, "booster_"):
            try: feat_names = list(model.booster_.feature_name())
            except: feat_names = None
            # Ğ”Ğ»Ñ CatBoost Ñ„Ğ¾Ğ»Ğ±ÑĞºĞ° Ğ¿Ñ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ„Ğ¸Ñ‡ Ğ¸Ğ· metrics_global_catboost.json
            if use_catboost_fallback and (feat_names is None):
                cb_feat = None
                meta_path = Path("data_dw") / "metrics_global_catboost.json"
                if meta_path.exists():
                    try:
                        cb_feat = json.loads(meta_path.read_text(encoding="utf-8")).get("features")
                    except Exception:
                        cb_feat = None
                feat_names = cb_feat or [c for c in df_pair.columns if c not in ("id","sales","date") and not np.issubdtype(df_pair[c].dtype, np.datetime64)]

            if feat_names is None:
                st.error("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ„Ğ¸Ñ‡ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.")
            else:
                for f in feat_names:
                    if f not in df_pair.columns: df_pair[f] = 0.0
                tail = df_pair.tail(int(back_days)).copy()
                X_tail = tail[feat_names]; y_tail = tail["sales"].values
                # ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ¹ (point) Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ»Ğ¸ CatBoost
                try:
                    y_pred = model.predict(X_tail)
                except Exception:
                    # CatBoost Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ Pool, Ğ½Ğ¾ predict Ğ¿Ğ¾ DataFrame Ñ‚Ğ¾Ğ¶Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚; fallback Ğ½Ğ° numpy
                    y_pred = model.predict(X_tail.values)

                # ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ»Ğ¸Ğ½Ğ¸Ñ XGBoost per-SKU, ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
                y_pred_xgb = None
                if xgb_ps_path.exists():
                    try:
                        mdl_xgb_ps = joblib.load(xgb_ps_path)
                        feat_xps = getattr(mdl_xgb_ps, 'feature_names_in_', None)
                        cols_xps = list(feat_xps) if feat_xps is not None else feat_names
                        for f in cols_xps:
                            if f not in tail.columns:
                                tail[f] = 0.0
                        X_tail_xps = tail[cols_xps]
                        y_pred_xgb = mdl_xgb_ps.predict(X_tail_xps)
                    except Exception:
                        y_pred_xgb = None
                # ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ P50 Ğ¸ P90 Ğ´Ğ»Ñ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ ĞºĞ¾Ñ€Ğ¸Ğ´Ğ¾Ñ€Ğ°
                q50_path = Path("models") / f"{int(store_bt)}__{str(family_bt).replace(' ', '_')}__q50.joblib"
                q90_path = Path("models") / f"{int(store_bt)}__{str(family_bt).replace(' ', '_')}__q90.joblib"
                q50_pred = q90_pred = None
                if not use_catboost_fallback:  # ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ»Ğ¸ ĞµÑÑ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñƒ per-SKU Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
                    try:
                        if q50_path.exists():
                            mdl_q50 = joblib.load(q50_path)
                            q50_pred = mdl_q50.predict(X_tail)
                        if q90_path.exists():
                            mdl_q90 = joblib.load(q90_path)
                            q90_pred = mdl_q90.predict(X_tail)
                    except Exception as e:
                        st.warning(f"ĞšĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ: {e}")
                import matplotlib.pyplot as plt
                # Ğ’ĞºĞ»Ğ°Ğ´ĞºĞ° Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ¼ Ğ¿Ğ¾ Ğ´Ğ½ÑĞ¼ Ğ¸ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞ° Ñ Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
                tabs = st.tabs(["ĞŸĞ¾ Ğ´Ğ½ÑĞ¼", "ĞĞ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸Ğ¸ (Ğ½ĞµĞ´ĞµĞ»Ğ¸/Ğ¼ĞµÑÑÑ†Ñ‹)"])

                # Ğ’ĞºĞ»Ğ°Ğ´ĞºĞ° 1: ĞŸĞ¾ Ğ´Ğ½ÑĞ¼
                with tabs[0]:
                    fig1 = plt.figure(figsize=(12,4))
                    plt.plot(tail["date"], y_tail, label="Ğ¤Ğ°ĞºÑ‚")
                    plt.plot(tail["date"], y_pred, label="ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· (LGBM/CatBoost)")
                    if y_pred_xgb is not None and show_xgbps_bt:
                        plt.plot(tail["date"], y_pred_xgb, label="XGBoost per-SKU")
                    # Ğ•ÑĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ñ‹ â€” Ñ€Ğ¸ÑÑƒĞµĞ¼ ĞºĞ¾Ñ€Ğ¸Ğ´Ğ¾Ñ€
                    if q50_pred is not None and q90_pred is not None:
                        plt.fill_between(tail["date"], q50_pred, q90_pred, color="orange", alpha=0.25, label="P50â€“P90")
                    title = "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸: Ñ„Ğ°ĞºÑ‚ vs Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·"
                    if 'use_catboost_fallback' in locals() and use_catboost_fallback:
                        title += " â€” CatBoost fallback"
                        # Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ğ¾Ğ¼ĞµÑ‚ĞºĞ° Ğ½Ğ° Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞµ
                        plt.text(0.01, 0.98, "CatBoost fallback", transform=plt.gca().transAxes,
                                 fontsize=10, va='top', ha='left', color='white',
                                 bbox=dict(facecolor='#6c757d', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.3'))
                    plt.title(title); plt.xlabel("Ğ”Ğ°Ñ‚Ğ°"); plt.ylabel("ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸")
                    plt.legend(); plt.grid()
                    st.pyplot(fig1)
                mae = np.mean(np.abs(y_tail - y_pred))
                denom = np.where(y_tail == 0, 1, y_tail)
                mape = np.mean(np.abs((y_tail - y_pred) / denom)) * 100.0
                st.metric("MAE (tail)", f"{mae:.3f} ÑˆÑ‚.")
                st.metric("MAPE (tail, %)", f"{mape:.2f}%")
                if y_pred_xgb is not None and show_xgbps_bt:
                        mae_xgb = np.mean(np.abs(y_tail - y_pred_xgb))
                        mape_xgb = np.mean(np.abs((y_tail - y_pred_xgb) / denom)) * 100.0
                        st.metric("MAE XGBoost (tail)", f"{mae_xgb:.3f} ÑˆÑ‚.")
                        st.metric("MAPE XGBoost (tail, %)", f"{mape_xgb:.2f}%")
                # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ñ€Ğ¸Ğ´Ğ¾Ñ€Ğ° (Ğ¿Ğ¾ Ğ´Ğ½ÑĞ¼), ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
                if q50_pred is not None and q90_pred is not None:
                    # Ğ´Ğ¾Ğ»Ñ Ñ‚Ğ¾Ñ‡ĞµĞº Ñ„Ğ°ĞºÑ‚Ğ° Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ [P50, P90]
                    inside = np.mean((y_tail >= np.minimum(q50_pred, q90_pred)) & (y_tail <= np.maximum(q50_pred, q90_pred)))
                    avg_width = float(np.mean(np.abs(q90_pred - q50_pred)))
                    st.metric("Ğ”Ğ¾Ğ»Ñ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ Ñ„Ğ°ĞºÑ‚Ğ° (P50â€“P90)", f"{inside*100:.1f}%")
                    st.metric("Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ ÑˆĞ¸Ñ€Ğ¸Ğ½Ğ° ĞºĞ¾Ñ€Ğ¸Ğ´Ğ¾Ñ€Ğ°", f"{avg_width:.3f} ÑˆÑ‚.")

                # Ğ’ĞºĞ»Ğ°Ğ´ĞºĞ° 2: ĞĞ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ (Ğ½ĞµĞ´ĞµĞ»Ğ¸/Ğ¼ĞµÑÑÑ†Ñ‹)
                with tabs[1]:
                    st.caption("ĞĞ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ñƒ (ÑÑƒĞ¼Ğ¼Ğ° Ğ¿Ğ¾ Ğ´Ğ½ÑĞ¼)")
                    period = st.radio("ĞŸĞµÑ€Ğ¸Ğ¾Ğ´", ["ĞĞµĞ´ĞµĞ»Ñ", "ĞœĞµÑÑÑ†"], horizontal=True)
                    agg_mode = st.radio("ĞĞ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ", ["Ğ¡ÑƒĞ¼Ğ¼Ğ°", "Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ"], horizontal=True)
                    freq = "W" if period == "ĞĞµĞ´ĞµĞ»Ñ" else "M"
                    # Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ DataFrame Ğ´Ğ»Ñ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸Ğ¸
                    df_plot = pd.DataFrame({
                        "date": tail["date"].values,
                        "y_true": y_tail,
                        "y_pred": y_pred,
                    })
                    if q50_pred is not None and q90_pred is not None:
                        df_plot["p50"] = q50_pred
                        df_plot["p90"] = q90_pred
                    # ĞĞ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑÑƒĞ¼Ğ¼Ğ¾Ğ¹ Ğ¿Ğ¾ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ñƒ
                    grouped = df_plot.set_index("date").groupby(pd.Grouper(freq=freq))
                    if agg_mode == "Ğ¡ÑƒĞ¼Ğ¼Ğ°":
                        g = grouped.sum().reset_index()
                    else:
                        g = grouped.mean().reset_index()
                    # Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ‚Ğ¾Ğ²
                    fig2 = plt.figure(figsize=(12,4))
                    plt.plot(g["date"], g["y_true"], label="Ğ¤Ğ°ĞºÑ‚ (agg)")
                    plt.plot(g["date"], g["y_pred"], label="ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· (agg)")
                    if y_pred_xgb is not None and show_xgbps_bt:
                        # Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€ÑƒĞµĞ¼ XGB Ğ¿Ğ¾ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ñƒ
                        g_x = (pd.DataFrame({"date": tail["date"].values, "y": y_pred_xgb})
                                 .set_index("date").groupby(pd.Grouper(freq=freq)).sum().reset_index())
                        plt.plot(g_x["date"], g_x["y"], label="XGBoost per-SKU (agg)")
                    if "p50" in g.columns and "p90" in g.columns:
                        plt.fill_between(g["date"], g["p50"], g["p90"], color="orange", alpha=0.25, label="P50â€“P90 (agg)")
                    ylabel = "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸ (ÑÑƒĞ¼Ğ¼Ğ°)" if agg_mode == "Ğ¡ÑƒĞ¼Ğ¼Ğ°" else "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸ (ÑÑ€ĞµĞ´Ğ½ĞµĞµ)"
                    agg_title = f"ĞĞ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸: {period.lower()}"
                    if 'use_catboost_fallback' in locals() and use_catboost_fallback:
                        agg_title += " â€” CatBoost fallback"
                        plt.text(0.01, 0.98, "CatBoost fallback", transform=plt.gca().transAxes,
                                 fontsize=10, va='top', ha='left', color='white',
                                 bbox=dict(facecolor='#6c757d', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.3'))
                    plt.title(agg_title); plt.xlabel("ĞŸĞµÑ€Ğ¸Ğ¾Ğ´"); plt.ylabel(ylabel)
                    plt.legend(); plt.grid()
                    st.pyplot(fig2)

                    # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ½Ğ° Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ñ€ÑĞ´Ñƒ
                    y_true_agg = g["y_true"].values
                    y_pred_agg = g["y_pred"].values
                    mae_agg = np.mean(np.abs(y_true_agg - y_pred_agg))
                    denom_agg = np.where(y_true_agg == 0, 1, y_true_agg)
                    mape_agg = np.mean(np.abs((y_true_agg - y_pred_agg) / denom_agg)) * 100.0
                    st.metric("MAE (agg)", f"{mae_agg:.3f} ÑˆÑ‚.")
                    st.metric("MAPE (agg, %)", f"{mape_agg:.2f}%")

st.markdown("---")
st.subheader("ğŸ” Ğ’Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² (feature importance)")

colF1, colF2 = st.columns(2)
with colF1:
    store_imp = st.number_input("store_nbr (FI)", min_value=1, step=1, value=int(store_bt))
with colF2:
    family_imp = st.text_input("family (FI)", value=family_bt)

imp_path = Path("models") / f"{int(store_imp)}__{str(family_imp).replace(' ', '_')}.joblib"
if not imp_path.exists():
    st.info(f"ĞĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ FI: {imp_path.name}")
else:
    try:
        mdl = joblib.load(imp_path)
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¸Ğ¼ĞµĞ½Ğ° Ñ„Ğ¸Ñ‡ Ğ¸ Ğ¸Ñ… Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ (gain)
        if hasattr(mdl, "booster_"):
            names = list(mdl.booster_.feature_name())
            gains = mdl.booster_.feature_importance(importance_type="gain")
        else:
            # fallback: ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚ booster_ (Ñ€ĞµĞ´ĞºĞ¾)
            names = getattr(mdl, "feature_name_", [])
            gains = getattr(mdl, "feature_importances_", [])
        import pandas as pd
        df_fi = pd.DataFrame({"feature": names, "gain": gains}).sort_values("gain", ascending=False).head(15)
        st.dataframe(df_fi, use_container_width=True)
        st.bar_chart(df_fi.set_index("feature"))
    except Exception as e:
        st.error(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸: {e}")

st.markdown("---")

# ----------------------- Ğ‘Ğ¸Ğ·Ğ½ĞµÑ: ROP / Safety Stock -----------------------
st.subheader("ğŸ“¦ Ğ Ğ°ÑÑ‡Ñ‘Ñ‚ ROP / Safety Stock")
colp1, colp2 = st.columns(2)
with colp1:
    lead_time_days = st.number_input("Lead time (Ğ´Ğ½ĞµĞ¹)", min_value=1, value=2, step=1, key="lead_time_days")
    service_level = st.slider("Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ ÑĞµÑ€Ğ²Ğ¸ÑĞ°", min_value=0.80, max_value=0.99, value=0.95, step=0.01, key="service_level")
    calc = st.button("Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ ROP/SS", key="calc_rop")
with colp2:
    st.caption("Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ P50/P90, ĞµÑĞ»Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ñ‹. Ğ˜Ğ½Ğ°Ñ‡Ğµ â€” ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ïƒ â‰ˆ 0.25Â·mean.")

if 'features_text_buf' in st.session_state and st.session_state.get('features_text_buf') and st.session_state.get('calc_rop'):
    try:
        feats_body = json.loads(st.session_state['features_text_buf'])
        body = {
            "store_nbr": int(store_nbr),
            "family": str(family),
            "features": feats_body,
            "lead_time_days": int(st.session_state.get('lead_time_days', 2)),
            "service_level": float(st.session_state.get('service_level', 0.95)),
        }
        r = requests.post(f"{API_URL}/reorder_point", json=body, timeout=10)
        if r.ok:
            data = r.json()
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("Daily mean (API), ÑˆÑ‚.", f"{data['daily_mean']:.2f}")
            m2.metric("Sigma (API), ÑˆÑ‚.", f"{data['sigma_daily']:.2f}")
            m3.metric("Safety Stock (API), ÑˆÑ‚.", f"{data['safety_stock']:.2f}")
            m4.metric("ROP (API), ÑˆÑ‚.", f"{data['reorder_point']:.2f}")
            st.caption(f"quantiles_used={data.get('quantiles_used', False)} | z={data.get('service_level_z')}")
        else:
            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° API: {r.status_code} {r.text}")
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ñ€Ğ°ÑÑ‡Ñ‘Ñ‚Ğ°: {e}")

# ----------------------- ĞŸĞ»Ğ°Ğ½ Ğ·Ğ°Ğ¿Ğ°ÑĞ¾Ğ² (Ğ¾Ñ„Ğ»Ğ°Ğ¹Ğ½ ÑĞºÑ€Ğ¸Ğ¿Ñ‚) -----------------------
st.subheader("ğŸ“¦ ĞŸĞ»Ğ°Ğ½ Ğ·Ğ°Ğ¿Ğ°ÑĞ¾Ğ² (Ğ±ĞµĞ¹ÑĞ»Ğ°Ğ¹Ğ½ Ğ¸Ğ· Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ… Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶)")
stock_csv = Path("data_dw/stock_plan.csv")
if stock_csv.exists():
    try:
        df_stock = pd.read_csv(stock_csv)
        st.dataframe(df_stock, use_container_width=True)
        st.download_button(
            "â¬‡ï¸ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ stock_plan.csv",
            data=df_stock.to_csv(index=False).encode("utf-8"),
            file_name="stock_plan.csv",
            mime="text/csv",
        )
    except Exception as e:
        st.error(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ stock_plan.csv: {e}")
else:
    st.info("Ğ¤Ğ°Ğ¹Ğ» stock_plan.csv Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸: make stock")

# ----------------------- SHAP ĞŸÑ€ĞµĞ´Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ -----------------------
st.subheader("ğŸ” SHAP â€” Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² (Ğ¿Ñ€ĞµĞ´Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€)")
try:
    store_cur = int(store_nbr)
    family_cur = str(family)
except Exception:
    store_cur, family_cur = 1, "AUTOMOTIVE"
shap_png = Path("data_dw") / f"shap_summary_{store_cur}__{family_cur}.png"
shap_csv = Path("data_dw") / f"shap_top_{store_cur}__{family_cur}.csv"
cols_sh = st.columns(2)
with cols_sh[0]:
    if shap_png.exists():
        st.image(str(shap_png), caption=shap_png.name, use_column_width=True)
    else:
        st.info("SHAP ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°. Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞ¹ Ñ‡ĞµÑ€ĞµĞ· scripts/shap_report.py")
with cols_sh[1]:
    if shap_csv.exists():
        df_shap = pd.read_csv(shap_csv)
        st.dataframe(df_shap.head(25), use_container_width=True)
        st.download_button("â¬‡ï¸ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ shap_top.csv", data=df_shap.to_csv(index=False).encode('utf-8'), file_name=shap_csv.name, mime='text/csv')
    else:
        st.info("Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° SHAP Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°.")

st.subheader("ğŸ“‚ ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ data_raw (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸)")
raw_dir = Path("data_raw")
if not raw_dir.exists():
    st.info("ĞŸĞ°Ğ¿ĞºĞ° data_raw Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ¸ Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸ CSV: train.csv, transactions.csv, oil.csv, holidays_events.csv, stores.csv")
else:
    cols = st.columns(5)
    files = ["train.csv", "transactions.csv", "oil.csv", "holidays_events.csv", "stores.csv"]
    for i, fname in enumerate(files):
        p = raw_dir / fname
        with cols[i]:
            st.write(f"**{fname}**")
            if p.exists():
                try:
                    df = pd.read_csv(p, nrows=5)
                    st.dataframe(df, use_container_width=True)
                except Exception as e:
                    st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ: {e}")
            else:
                st.warning("ĞĞµÑ‚ Ñ„Ğ°Ğ¹Ğ»Ğ°")
