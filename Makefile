# –ü—Ä–æ—Å—Ç—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è .env, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.

# –í—ã–±–æ—Ä –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä–∞: –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π venv, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
# –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π venv, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å, –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö shell-–≤—ã—Ä–∞–∂–µ–Ω–∏–π
ifneq ("$(wildcard .venv/bin/python)", "")
PY := .venv/bin/python
else
PY := $(shell command -v python || echo python)
endif

ifneq ("$(wildcard .venv/bin/pip)", "")
PIP := .venv/bin/pip
else
PIP := $(shell command -v pip || echo pip)
endif

SHELL := /bin/bash
.ONESHELL:

.PHONY: help env validate etl features train api ui docker train_global train_global_xgb venv setup train_xgb train_one_xgb \
        lint typecheck test test-cov test-fast test-unit test-integration cov all dev-setup precommit-install \
        benchmark benchmark-fast lint-fix quality demo demo-full \
        optuna shap biz-metrics clean-artifacts clean-repo impact prices-template retrain-all \
        export-onnx biz-report clean-mlflow \
        batch-train-selected train-quantiles-selected export-eda model-summary shap-one

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
MLFLOW_PORT ?= 5000

# –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É –ø–æ –≤—Å–µ–º –∫–æ–º–∞–Ω–¥–∞–º
help: ## –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É –ø–æ –≤—Å–µ–º –∫–æ–º–∞–Ω–¥–∞–º
	@echo "üöÄ AZS + Retail Project - –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:"
	@echo ""
	@echo "üìä –û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏:"
	@echo "  validate     - –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
	@echo "  etl          - ETL –ø—Ä–æ—Ü–µ—Å—Å (CSV ‚Üí Parquet + DuckDB)"
	@echo "  features     - –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
	@echo "  train        - –û–±—É—á–µ–Ω–∏–µ per-SKU –º–æ–¥–µ–ª–µ–π LightGBM"
	@echo "  train_global - –û–±—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π CatBoost –º–æ–¥–µ–ª–∏"
	@echo "  train_global_xgb - –û–±—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π XGBoost –º–æ–¥–µ–ª–∏"
	@echo ""
	@echo "üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–æ–≤:"
	@echo "  api          - –ó–∞–ø—É—Å–∫ FastAPI —Å–µ—Ä–≤–µ—Ä–∞"
	@echo "  ui           - –ó–∞–ø—É—Å–∫ Streamlit UI"
	@echo "  docker       - –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ Docker Compose"
	@echo ""
	@echo "üß© –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:"
	@echo "  optuna       - Optuna-—Ç—é–Ω–∏–Ω–≥ LGBM per-SKU (best params + –º–æ–¥–µ–ª—å)"
	@echo "  shap         - SHAP –æ—Ç—á—ë—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø–∞—Ä—ã"
	@echo "  biz-metrics  - –ü–µ—Ä–µ–≤–æ–¥ MAPE –≤ –¥–µ–Ω—å–≥–∏ –∏ —Ä–∞—Å—á—ë—Ç SS/ROP"
	@echo "  export-onnx  - –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –ø–∞—Ä—ã –≤ ONNX (+INT8)"
	@echo "  biz-report   - –°–≤–æ–¥–Ω—ã–π –±–∏–∑–Ω–µ—Å-–æ—Ç—á—ë—Ç –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º (CSV)"
	@echo "  batch-train-selected - –û–±—É—á–∏—Ç—å per-SKU (LGBM+XGB) –¥–ª—è –ø–µ—Ä–≤—ã—Ö 20 –∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 10 –º–∞–≥–∞–∑–∏–Ω–æ–≤"
	@echo "  train-quantiles-selected - –û–±—É—á–∏—Ç—å –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ (P50/P90) –¥–ª—è —Ç–µ—Ö –∂–µ –ø–∞—Ä"
	@echo "  export-eda   - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å EDA-–≥—Ä–∞—Ñ–∏–∫–∏ (—Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å/–ø—Ä–æ–º–æ) –≤ docs/"
	@echo "  model-summary - –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –≤ docs/model_comparison.csv"
	@echo "  shap-one     - SHAP –¥–ª—è –æ–¥–Ω–æ–π –ø–∞—Ä—ã (STORE/FAMILY)"
	@echo "     –ü–∞—Ä–∞–º–µ—Ç—Ä—ã batch/train-quantiles: STORE_LIST=\"1,2\" FAMILY_LIST=\"BEVERAGES,PRODUCE\" MAX_PAIRS=100 STOP_FILE=STOP_BATCH"
	@echo "  clean-mlflow - –£–¥–∞–ª–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã MLflow (mlflow.db, mlruns/)"
	@echo ""
	@echo "üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∫–∞—á–µ—Å—Ç–≤–æ:"
	@echo "  test         - –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"
	@echo "  test-cov     - –¢–µ—Å—Ç—ã —Å –ø–æ–∫—Ä—ã—Ç–∏–µ–º –∫–æ–¥–∞"
	@echo "  test-fast    - –ë—ã—Å—Ç—Ä—ã–µ —Ç–µ—Å—Ç—ã (–±–µ–∑ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö)"
	@echo "  test-unit    - –¢–æ–ª—å–∫–æ unit —Ç–µ—Å—Ç—ã"
	@echo "  test-integration - –¢–æ–ª—å–∫–æ integration —Ç–µ—Å—Ç—ã"
	@echo "  lint         - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞"
	@echo "  lint-fix     - –ê–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–∏–Ω—Ç–µ—Ä–∞"
	@echo "  typecheck    - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ (MyPy)"
	@echo "  quality      - –ü–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞"
	@echo ""
	@echo "‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:"
	@echo "  benchmark    - –ü–æ–ª–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –º–æ–¥–µ–ª–µ–π"
	@echo "  benchmark-fast - –ë—ã—Å—Ç—Ä—ã–π –±–µ–Ω—á–º–∞—Ä–∫"
	@echo ""
	@echo "üéØ –î–µ–º–æ –∏ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è:"
	@echo "  demo         - –ë—ã—Å—Ç—Ä–æ–µ –¥–µ–º–æ —Å –∏–≥—Ä—É—à–µ—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"
	@echo "  demo-full    - –ü–æ–ª–Ω–æ–µ –¥–µ–º–æ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏"
	@echo ""
	@echo "üîß –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞:"
	@echo "  venv         - –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è"
	@echo "  dev-setup    - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ dev-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
	@echo "  precommit-install - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ pre-commit —Ö—É–∫–æ–≤"
	@echo ""
	@echo "üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ:"
	@echo "  pairs        - –ü–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ä—ã (store_nbr, family)"
	@echo "  all          - validate ‚Üí etl ‚Üí features ‚Üí train ‚Üí test"
	@echo ""
	@echo "üí° –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:"
	@echo "  make help              - –≠—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞"
	@echo "  make demo-full         - –ü–æ–ª–Ω–æ–µ –¥–µ–º–æ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏"
	@echo "  make quality           - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞"
	@echo "  make benchmark         - –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
	@echo "  make slides-html       - –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML-—Å–ª–∞–π–¥—ã –∏–∑ docs/slides.md (pandoc)"
	@echo "  make slides-pdf        - –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å PDF-—Å–ª–∞–π–¥—ã (—Ç—Ä–µ–±—É–µ—Ç—Å—è LaTeX)"

env:
	@[ -f .env ] && echo "Using .env" || echo "No .env found (using defaults)"

validate: env
	$(PY) validation.py

etl: env
	$(PY) etl.py

features: env
	$(PY) features.py

train: env
	# –ü—Ä–∏–º–µ—Ä: –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —á–µ—Ä–µ–∑ configs/train.yaml –∏/–∏–ª–∏ CLI
	$(PY) train_forecast.py \
	  --train $${RAW_DIR:-data_raw}/train.csv \
	  --transactions $${RAW_DIR:-data_raw}/transactions.csv \
	  --oil $${RAW_DIR:-data_raw}/oil.csv \
	  --holidays $${RAW_DIR:-data_raw}/holidays_events.csv \
	  --stores $${RAW_DIR:-data_raw}/stores.csv \
	  --config configs/train.yaml \
	  --lgb_objective $${LGB_OBJECTIVE:-l1} \
	  --tweedie_variance_power $${TWEEDIE_POWER:-1.2}

train_global: env
	$(PY) train_global_catboost.py \
	  --train $${RAW_DIR:-data_raw}/train.csv \
	  --transactions $${RAW_DIR:-data_raw}/transactions.csv \
	  --oil $${RAW_DIR:-data_raw}/oil.csv \
	  --holidays $${RAW_DIR:-data_raw}/holidays_events.csv \
	  --stores $${RAW_DIR:-data_raw}/stores.csv \
	  --valid_days $${VALID_DAYS:-28}

train_global_xgb: env
	$(PY) train_global_xgboost.py \
	  --train $${RAW_DIR:-data_raw}/train.csv \
	  --transactions $${RAW_DIR:-data_raw}/transactions.csv \
	  --oil $${RAW_DIR:-data_raw}/oil.csv \
	  --holidays $${RAW_DIR:-data_raw}/holidays_events.csv \
	  --stores $${RAW_DIR:-data_raw}/stores.csv \
	  --valid_days $${VALID_DAYS:-28}

api: env
	$(PY) -m uvicorn service.app:app --reload

ui: env
	$(PY) -m streamlit run ui/dashboard.py

docker: env
	docker compose up --build

# –ë—ã—Å—Ç—Ä—ã–π –¥–µ–º–æ-—Ä–µ–∂–∏–º: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–≥—Ä—É—à–µ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—É—á–∏—Ç—å top-N
demo: env
	$(PY) scripts/generate_toy_data.py
	$(PY) validation.py
	$(PY) etl.py
	$(PY) features.py
	$(PY) train_forecast.py \
	  --train data_raw/train.csv \
	  --transactions data_raw/transactions.csv \
	  --oil data_raw/oil.csv \
	  --holidays data_raw/holidays_events.csv \
	  --stores data_raw/stores.csv \
	  --models_dir models \
	  --warehouse_dir data_dw \
	  --top_n_sku 4 \
	  --top_recent_days 60 \
	  --valid_days 14

# –°–æ–∑–¥–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
venv:
	@echo "Creating venv in .venv ..."
	@(python3 -m venv .venv || python -m venv .venv)
	@.venv/bin/python -m pip install -U pip setuptools wheel
	@.venv/bin/pip install -r requirements.txt
	@echo "OK: venv ready. Use: source .venv/bin/activate"

setup: venv

train_xgb: env
	$(PY) train_forecast_xgb.py \
	  --train $${RAW_DIR:-data_raw}/train.csv \
	  --transactions $${RAW_DIR:-data_raw}/transactions.csv \
	  --oil $${RAW_DIR:-data_raw}/oil.csv \
	  --holidays $${RAW_DIR:-data_raw}/holidays_events.csv \
	  --stores $${RAW_DIR:-data_raw}/stores.csv \
	  --top_n_sku $${TOP_N_SKU:-50} \
	  --top_recent_days $${TOP_RECENT_DAYS:-90} \
	  --valid_days $${VALID_DAYS:-28}

train_one_xgb: env
	@if [ -z "$(STORE)" ] || [ -z "$(FAMILY)" ]; then \
	  echo "ERROR: —É–∫–∞–∂–∏—Ç–µ STORE –∏ FAMILY, –Ω–∞–ø—Ä–∏–º–µ—Ä: make train_one_xgb STORE=2 FAMILY=AUTOMOTIVE"; \
	  exit 1; \
	else \
	  $(PY) scripts/train_one_pair_xgb.py \
	    --store $(STORE) \
	    --family "$(FAMILY)" \
	    --valid_days $${VALID_DAYS:-28} \
	    --models_dir $${MODELS_DIR:-models} \
	    --data_dir $${DATA_DIR:-data_raw} ; \
	fi


# –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–∞—Ä (store_nbr, family) –∏–∑ train.csv
pairs: env
	@echo "–ü–µ—Ä–≤—ã–µ 30 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ä –∏–∑ $${DATA_DIR:-data_raw}/train.csv"; \
	$(PY) - <<-'PY'
		import os, pandas as pd
		p = os.environ.get('DATA_DIR', 'data_raw')
		try:
	    	df = pd.read_csv(f"{p}/train.csv")
	    	pairs = df[['store_nbr','family']].drop_duplicates().head(30)
	    	print(pairs.to_string(index=False))
		except Exception as e:
	    	print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {p}/train.csv: {e}")
	PY

# ---- –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞: –ª–∏–Ω—Ç–µ—Ä—ã, —Ç–∏–ø—ã, —Ç–µ—Å—Ç—ã ----

lint: env ## –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–¥–∞ (–±–µ–∑ –∞–≤—Ç–æ-—Ñ–∏–∫—Å)
	@echo "Running ruff and black checks..."
	$(PY) -m ruff check .
	$(PY) -m black --check .

lint-fix: env ## –ê–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–∏–Ω—Ç–µ—Ä–∞
	@echo "Running ruff and black with auto-fix..."
	$(PY) -m ruff check . --fix
	$(PY) -m black .

typecheck: env
	@echo "Running mypy..."
	$(PY) -m mypy . --ignore-missing-imports

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞
test: env ## –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
	@echo "Running tests (pytest)..."
	$(PY) -m pytest -q

test-cov: env ## –¢–µ—Å—Ç—ã —Å –ø–æ–∫—Ä—ã—Ç–∏–µ–º
	@echo "Running tests with coverage..."
	$(PY) -m pytest --cov=. --cov-report=html:htmlcov --cov-report=term-missing

test-fast: env ## –ë—ã—Å—Ç—Ä—ã–µ —Ç–µ—Å—Ç—ã (–±–µ–∑ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö)
	@echo "Running fast tests..."
	$(PY) -m pytest -m "not slow" -q

test-unit: env ## –¢–æ–ª—å–∫–æ unit —Ç–µ—Å—Ç—ã
	@echo "Running unit tests..."
	$(PY) -m pytest -m "unit" -q

test-integration: env ## –¢–æ–ª—å–∫–æ integration —Ç–µ—Å—Ç—ã
	@echo "Running integration tests..."
	$(PY) -m pytest -m "integration" -q

cov: test-cov ## –ê–ª–∏–∞—Å –¥–ª—è test-cov

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
benchmark: env ## –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
	@echo "Running full benchmark..."
	$(PY) scripts/performance_monitor.py --generate-report --generate-plot

benchmark-fast: env ## –ë—ã—Å—Ç—Ä—ã–π –±–µ–Ω—á–º–∞—Ä–∫
	@echo "Running fast benchmark..."
	$(PY) scripts/performance_monitor.py --test-size 100

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞
quality: env ## –ü–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
	@echo "Running full quality check..."
	$(MAKE) lint
	$(MAKE) typecheck
	$(MAKE) test

# –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏
demo-full: env ## –ü–æ–ª–Ω–æ–µ –¥–µ–º–æ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏
	@echo "Running full demo for presentation..."
	$(MAKE) validate
	$(MAKE) etl
	$(MAKE) features
	$(MAKE) train
	$(MAKE) benchmark
	$(MAKE) api
	$(MAKE) ui

precommit-install:
	@echo "Installing pre-commit hooks..."
	@([ -x .venv/bin/pre-commit ] && .venv/bin/pre-commit install) || pre-commit install

dev-setup: venv
	@echo "Installing dev dependencies..."
	@.venv/bin/pip install -r requirements-dev.txt
	@.venv/bin/pre-commit install || true

all: validate etl features train test

# --- Repo cleanup helpers ---
.PHONY: clean-artifacts clean-repo

clean-artifacts: ## –£–¥–∞–ª–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã (–±–µ–∑ git)
	rm -rf .pytest_cache __pycache__ tests/__pycache__ service/__pycache__
	rm -rf data_raw/* data_dw/* models/*

clean-repo: ## –£–±—Ä–∞—Ç—å —Ç—è–∂—ë–ª—ã–µ –∫–∞—Ç–∞–ª–æ–≥–∏ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ git (—Ñ–∞–π–ª—ã –æ—Å—Ç–∞–Ω—É—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ) ‚Äî –¢–†–ï–ë–£–ï–¢ CONFIRM=1
	@if [ "$(CONFIRM)" != "1" ]; then \
	  echo "‚ö†Ô∏è  –≠—Ç–∞ —Ü–µ–ª—å –∏–∑–º–µ–Ω–∏—Ç –∏–Ω–¥–µ–∫—Å git (git rm --cached). –ó–∞–ø—É—Å—Ç–∏—Ç–µ: make clean-repo CONFIRM=1"; \
	  exit 1; \
	fi
	@echo "Cleaning git index from heavy artifacts..."
	- git rm -r --cached .venv .pytest_cache __pycache__ tests/__pycache__ service/__pycache__ .idea mlruns || true
	- git rm -r --cached data_raw/* data_dw/* models/* || true
	- find . -name .DS_Store -print0 | xargs -0 git rm --cached -f || true
	@echo "Done. Commit the changes: git commit -m 'chore: cleanup artifacts'"

# ---- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–ª–∏: Optuna / SHAP / –ë–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏ ----

optuna: env ## Optuna-—Ç—é–Ω–∏–Ω–≥ LGBM per-SKU (STORE/FAMILY –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã)
	@echo "Running Optuna tuning..."
	$(PY) experiments/tune_optuna.py \
	  --train $${RAW_DIR:-data_raw}/train.csv \
	  --transactions $${RAW_DIR:-data_raw}/transactions.csv \
	  --oil $${RAW_DIR:-data_raw}/oil.csv \
	  --holidays $${RAW_DIR:-data_raw}/holidays_events.csv \
	  --stores $${RAW_DIR:-data_raw}/stores.csv \
	  $$( [ -n "$(STORE)" ] && echo --store $(STORE) ) \
	  $$( [ -n "$(FAMILY)" ] && echo --family "$(FAMILY)" ) \
	  --valid_days $${VALID_DAYS:-28} \
	  --n_trials $${N_TRIALS:-50}

shap: env ## SHAP –æ—Ç—á—ë—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ (—Ç—Ä–µ–±—É–µ—Ç STORE –∏ FAMILY)
	@if [ -z "$(STORE)" ] || [ -z "$(FAMILY)" ]; then \
	  echo "ERROR: —É–∫–∞–∂–∏—Ç–µ STORE –∏ FAMILY, –Ω–∞–ø—Ä–∏–º–µ—Ä: make shap STORE=1 FAMILY=AUTOMOTIVE"; \
	  exit 1; \
	fi
	$(PY) scripts/shap_report.py \
	  --store $(STORE) --family "$(FAMILY)" \
	  --train $${RAW_DIR:-data_raw}/train.csv \
	  --transactions $${RAW_DIR:-data_raw}/transactions.csv \
	  --oil $${RAW_DIR:-data_raw}/oil.csv \
	  --holidays $${RAW_DIR:-data_raw}/holidays_events.csv \
	  --stores $${RAW_DIR:-data_raw}/stores.csv \
	  $$( [ -n "$(SHAP_SAMPLE)" ] && echo --sample $(SHAP_SAMPLE) )

biz-metrics: env ## MAPE‚Üí–¥–µ–Ω—å–≥–∏ –∏ —Ä–∞—Å—á—ë—Ç SS/ROP (—Ç—Ä–µ–±—É–µ—Ç STORE/FAMILY/PRICE)
	@if [ -z "$(STORE)" ] || [ -z "$(FAMILY)" ] || [ -z "$(PRICE)" ]; then \
	  echo "ERROR: —É–∫–∞–∂–∏—Ç–µ STORE, FAMILY –∏ PRICE, –Ω–∞–ø—Ä–∏–º–µ—Ä: make biz-metrics STORE=1 FAMILY=AUTOMOTIVE PRICE=3.5"; \
	  exit 1; \
	fi
	$(PY) scripts/business_metrics.py \
	  --store $(STORE) --family "$(FAMILY)" \
	  --price $(PRICE) \
	  --margin_rate $${MARGIN_RATE:-0.25} \
	  --holding_cost $${HOLDING_COST:-0.05} \
	  --lead_time_days $${LEAD_TIME_DAYS:-2} \
	  --service_level $${SERVICE_LEVEL:-0.95}

# –û—Ç—á—ë—Ç –ø–æ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–º—É —ç—Ñ—Ñ–µ–∫—Ç—É –Ω–∞ –≤—Å—ë–º –¥–∞—Ç–∞—Å–µ—Ç–µ (–ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º)
impact: env ## –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å business impact report (CSV –∏ —Å–≤–æ–¥–∫–∞ –≤ –∫–æ–Ω—Å–æ–ª–∏)
	$(PY) scripts/business_impact_report.py \
	  --train $${RAW_TRAIN:-data_raw/train.csv} \
	  --metrics $${METRICS_CSV:-data_dw/metrics_per_sku.csv} \
	  --price_csv $${PRICE_CSV:-configs/prices.csv} \
	  --lead_time_days $${LEAD_TIME_DAYS:-2} \
	  --service_level $${SERVICE_LEVEL:-0.95} \
	  --tail_days $${TAIL_DAYS:-30} \
	  --valid_days $${VALID_DAYS:-28} \
	  --out_csv $${OUT_CSV:-data_dw/business_impact_report.csv}

prices-template: env ## –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —à–∞–±–ª–æ–Ω —Ü–µ–Ω/–º–∞—Ä–∂–∏/—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ family –≤ configs/prices.csv
	$(PY) scripts/generate_prices_template.py --train $${RAW_TRAIN:-data_raw/train.csv} --out $${OUT_PRICES:-configs/prices.csv}

# –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX (—Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π)
export-onnx: env ## –≠–∫—Å–ø–æ—Ä—Ç per-SKU –º–æ–¥–µ–ª–∏ –≤ ONNX (—Ç—Ä–µ–±—É–µ—Ç STORE/FAMILY; QUANTIZE=1 –¥–ª—è INT8)
	@if [ -z "$(STORE)" ] || [ -z "$(FAMILY)" ]; then \
	  echo "ERROR: —É–∫–∞–∂–∏—Ç–µ STORE –∏ FAMILY, –Ω–∞–ø—Ä–∏–º–µ—Ä: make export-onnx STORE=1 FAMILY=AUTOMOTIVE [QUANTIZE=1]"; \
	  exit 1; \
	fi
	$(PY) scripts/export_onnx.py --store $(STORE) --family "$(FAMILY)" $$( [ "$(QUANTIZE)" = "1" ] && echo --quantize )

# –°–≤–æ–¥–Ω—ã–π –±–∏–∑–Ω–µ—Å-–æ—Ç—á—ë—Ç: CSV —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –≤–ª–∏—è–Ω–∏—è (—Å–º. scripts/business_impact_report.py)
biz-report: env ## –°–≤–æ–¥–Ω—ã–π –±–∏–∑–Ω–µ—Å-–æ—Ç—á—ë—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç configs/prices.csv)
	$(PY) scripts/business_impact_report.py \
	  --train $${RAW_TRAIN:-data_raw/train.csv} \
	  --metrics $${METRICS_CSV:-data_dw/metrics_per_sku.csv} \
	  --price_csv $${PRICE_CSV:-configs/prices.csv} \
	  --lead_time_days $${LEAD_TIME_DAYS:-2} \
	  --service_level $${SERVICE_LEVEL:-0.95} \
	  --tail_days $${TAIL_DAYS:-30} \
	  --valid_days $${VALID_DAYS:-28} \
	  --out_csv $${OUT_CSV:-data_dw/business_impact_report.csv}

# ---- –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ ----

batch-train-selected: env ## –ü–µ—Ä–≤–∞—è 5-–∫–∞ + –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –º–∞–≥–∞–∑–∏–Ω–æ–≤: per-SKU LGBM + per-SKU XGB
	$(PY) scripts/batch_train_selected.py

train-quantiles-selected: env ## –ü–µ—Ä–≤–∞—è 5-–∫–∞ + –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –º–∞–≥–∞–∑–∏–Ω–æ–≤: –æ–±—É—á–∏—Ç—å –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–µ LGBM (P50/P90)
	$(PY) scripts/train_quantiles_selected.py

export-eda: env ## –°–æ—Ö—Ä–∞–Ω–∏—Ç—å EDA-–≥—Ä–∞—Ñ–∏–∫–∏ –≤ docs/
	$(PY) scripts/export_eda_cli.py

model-summary: env ## –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π ‚Üí docs/model_comparison.csv
	$(PY) scripts/model_summary_cli.py

shap-one: env ## SHAP –æ—Ç—á—ë—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ (—Ç—Ä–µ–±—É–µ—Ç STORE –∏ FAMILY)
	@if [ -z "$(STORE)" ] || [ -z "$(FAMILY)" ]; then \
	  echo "ERROR: —É–∫–∞–∂–∏—Ç–µ STORE –∏ FAMILY, –Ω–∞–ø—Ä–∏–º–µ—Ä: make shap-one STORE=3 FAMILY=BEVERAGES"; \
	  exit 1; \
	fi
	PYTHONPATH=. $(PY) scripts/shap_report.py \
	  --store $(STORE) --family "$(FAMILY)" \
	  --train $${RAW_DIR:-data_raw}/train.csv \
	  --transactions $${RAW_DIR:-data_raw}/transactions.csv \
	  --oil $${RAW_DIR:-data_raw}/oil.csv \
	  --holidays $${RAW_DIR:-data_raw}/holidays_events.csv \
	  --stores $${RAW_DIR:-data_raw}/stores.csv

# –ü–æ–ª–Ω—ã–π –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (–æ—á–∏—Å—Ç–∫–∞ models + train LGBM/XGB per-SKU + –≥–ª–æ–±–∞–ª—å–Ω—ã–µ)
retrain-all: env ## –ü–æ–ª–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π (–æ—á–∏—â–∞–µ—Ç models/ –∫—Ä–æ–º–µ .gitkeep) ‚Äî –¢–†–ï–ë–£–ï–¢ CONFIRM=1
	@if [ "$(CONFIRM)" != "1" ]; then \
	  echo "‚ö†Ô∏è  –≠—Ç–∞ —Ü–µ–ª—å —É–¥–∞–ª–∏—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ models/. –î–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ: make retrain-all CONFIRM=1"; \
	  exit 1; \
	fi
	@echo "üì¶ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –º–æ–¥–µ–ª–µ–π..."
	@ts=$$(date +%Y%m%d_%H%M%S); mkdir -p backup_models_$${ts}; cp -a models/* backup_models_$${ts} 2>/dev/null || true; echo "backup ‚Üí backup_models_$${ts}"
	@echo "üßπ –û—á–∏—Å—Ç–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ models/ (–∫—Ä–æ–º–µ .gitkeep)"
	@find models -type f ! -name '.gitkeep' -delete || true
	@echo "‚ñ∂Ô∏è –û–±—É—á–µ–Ω–∏–µ per-SKU LGBM"; $(MAKE) train
	@echo "‚ñ∂Ô∏è –û–±—É—á–µ–Ω–∏–µ per-SKU XGB (—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º features.json)"; $(MAKE) train_xgb TOP_N_SKU=$${TOP_N_SKU:-50} TOP_RECENT_DAYS=$${TOP_RECENT_DAYS:-90} VALID_DAYS=$${VALID_DAYS:-28}
	@echo "‚ñ∂Ô∏è –û–±—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π CatBoost"; $(MAKE) train_global
	@echo "‚ñ∂Ô∏è –û–±—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π XGBoost"; $(MAKE) train_global_xgb
	@echo "‚úÖ –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ."

.PHONY: retrain-all-safe
retrain-all-safe: env ## –î–æ–æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏ models/ (LGBM/XGB per-SKU + –≥–ª–æ–±–∞–ª—å–Ω—ã–µ)
	@echo "‚ñ∂Ô∏è –û–±—É—á–µ–Ω–∏–µ per-SKU LGBM"; $(MAKE) train
	@echo "‚ñ∂Ô∏è –û–±—É—á–µ–Ω–∏–µ per-SKU XGB"; $(MAKE) train_xgb TOP_N_SKU=$${TOP_N_SKU:-50} TOP_RECENT_DAYS=$${TOP_RECENT_DAYS:-90} VALID_DAYS=$${VALID_DAYS:-28}
	@echo "‚ñ∂Ô∏è –û–±—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π CatBoost"; $(MAKE) train_global
	@echo "‚ñ∂Ô∏è –û–±—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π XGBoost"; $(MAKE) train_global_xgb
	@echo "‚úÖ –ì–æ—Ç–æ–≤–æ –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏."

# --- –ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è: —Å–±–æ—Ä–∫–∞ —Å–ª–∞–π–¥–æ–≤ (—Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π pandoc) ---
.PHONY: slides-html slides-pdf
slides-html:
	@echo "Building HTML slides (Pandoc + revealjs via CDN)..."
	pandoc -t revealjs -s -V theme=white -V revealjs-url=https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.0.4 \
	  -o docs/slides.html docs/slides.md
	@echo "OK: docs/slides.html"

slides-pdf:
	@echo "Building PDF slides (Pandoc Beamer; requires LaTeX)..."
	pandoc -t beamer -V aspectratio=169 -o docs/slides.pdf docs/slides.md
	@echo "OK: docs/slides.pdf"
